#!/usr/bin/env bun
/**
 * Full On-Chain E2E Test - Real Proof Verification
 *
 * Complete flow:
 * 1. Add demo deposit (commitment to tree)
 * 2. Fetch on-chain tree state
 * 3. Compute valid merkle proof matching on-chain root
 * 4. Generate ZK proof with correct root
 * 5. Submit claim with UltraHonk verification
 *
 * Prerequisites:
 *   - solana-test-validator running
 *   - zVault and UltraHonk verifier deployed
 *
 * Run: bun run scripts/test-e2e-onchain.ts
 */

import {
  Connection,
  Keypair,
  PublicKey,
  Transaction,
  TransactionInstruction,
  SystemProgram,
  sendAndConfirmTransaction,
  ComputeBudgetProgram,
  LAMPORTS_PER_SOL,
} from "@solana/web3.js";
import {
  TOKEN_2022_PROGRAM_ID,
  getAssociatedTokenAddressSync,
  createAssociatedTokenAccountInstruction,
  getAccount,
} from "@solana/spl-token";
import * as fs from "fs";
import * as path from "path";
import { fileURLToPath } from "url";
import { keccak_256 } from "@noble/hashes/sha3.js";

// SDK imports
import {
  initProver,
  setCircuitPath,
  generateClaimProof,
  cleanupProver,
  initPoseidon,
  poseidonHashSync,
  computeUnifiedCommitmentSync,
  computeNullifierSync,
  hashNullifierSync,
  generateGrumpkinKeyPair,
  pointToCompressedBytes,
  grumpkinEcdh,
  encryptAmount,
  buildAddDemoStealthData,
  // Stealth model imports
  deriveKeysFromSeed,
  createStealthDeposit,
  createStealthMetaAddress,
  prepareClaimInputs,
  bytesToBigint,
  type ClaimInputs,
  type ZVaultKeys,
  type StealthMetaAddress,
  type ScannedNote,
} from "@zvault/sdk";

// Import prover functions for VK data
import {
  getVerificationKey,
  type CircuitType,
} from "../../sdk/dist/prover/web.js";

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// Configuration
const NETWORK = process.env.NETWORK || "localnet";
const DEFAULT_RPC_URLS: Record<string, string> = {
  localnet: "http://127.0.0.1:8899",
  devnet: "https://solana-devnet.g.alchemy.com/v2/y1zYW-ovVofq7OzZo0Z6IHenRnyq_Pbd",
};
const RPC_URL = process.env.RPC_URL || DEFAULT_RPC_URLS[NETWORK] || DEFAULT_RPC_URLS.localnet;
const TREE_DEPTH = 20;
const DEMO_AMOUNT = 10_000n;
const BN254_MODULUS = 21888242871839275222246405745257275088548364400416034343698204186575808495617n;

// Load config based on network
const configPath = path.join(__dirname, "..", NETWORK === "devnet" ? ".devnet-config.json" : ".localnet-config.json");
const mainConfigPath = path.join(__dirname, "..", "config.json");

// Instruction discriminators
const DISCRIMINATOR = {
  ADD_DEMO_STEALTH: 22,
  CLAIM: 9,
};

// Seeds
const SEEDS = {
  POOL_STATE: "pool_state",
  COMMITMENT_TREE: "commitment_tree",
  NULLIFIER: "nullifier",
  STEALTH: "stealth",
};

// =============================================================================
// Helpers
// =============================================================================

function log(msg: string) {
  console.log(`  ${msg}`);
}

function logSection(title: string) {
  console.log("\n" + "=".repeat(60));
  console.log(title);
  console.log("=".repeat(60));
}

function randomFieldElement(): bigint {
  const bytes = new Uint8Array(32);
  crypto.getRandomValues(bytes);
  return BigInt("0x" + Buffer.from(bytes).toString("hex")) % BN254_MODULUS;
}

function bigintToBytes32(n: bigint): Uint8Array {
  const hex = n.toString(16).padStart(64, "0");
  const bytes = new Uint8Array(32);
  for (let i = 0; i < 32; i++) {
    bytes[i] = parseInt(hex.slice(i * 2, i * 2 + 2), 16);
  }
  return bytes;
}

function bytes32ToBigint(bytes: Uint8Array): bigint {
  let hex = "0x";
  for (const b of bytes) {
    hex += b.toString(16).padStart(2, "0");
  }
  return BigInt(hex);
}

async function loadKeypair(keyPath: string): Promise<Keypair> {
  const absolutePath = keyPath.replace("~", process.env.HOME || "");
  const secretKey = JSON.parse(fs.readFileSync(absolutePath, "utf-8"));
  return Keypair.fromSecretKey(Uint8Array.from(secretKey));
}

// =============================================================================
// PDA Derivation
// =============================================================================

function derivePoolStatePDA(programId: PublicKey): [PublicKey, number] {
  return PublicKey.findProgramAddressSync(
    [Buffer.from(SEEDS.POOL_STATE)],
    programId
  );
}

function deriveCommitmentTreePDA(programId: PublicKey): [PublicKey, number] {
  return PublicKey.findProgramAddressSync(
    [Buffer.from(SEEDS.COMMITMENT_TREE)],
    programId
  );
}

function deriveNullifierPDA(nullifierHash: Uint8Array, programId: PublicKey): [PublicKey, number] {
  return PublicKey.findProgramAddressSync(
    [Buffer.from(SEEDS.NULLIFIER), nullifierHash],
    programId
  );
}

function deriveStealthAnnouncementPDA(ephemeralPub: Uint8Array, programId: PublicKey): [PublicKey, number] {
  return PublicKey.findProgramAddressSync(
    [Buffer.from(SEEDS.STEALTH), Buffer.from(ephemeralPub.slice(1, 33))],
    programId
  );
}

// =============================================================================
// On-Chain State Parsing
// =============================================================================

interface CommitmentTreeState {
  bump: number;
  currentRoot: bigint;
  nextIndex: bigint;
  frontier: bigint[];
}

function parseCommitmentTree(data: Buffer): CommitmentTreeState {
  // Layout: disc(1) + bump(1) + padding(6) = 8 bytes header
  // Then: current_root(32) + next_index(8) + frontier([32]*20) + root_history([32]*100)
  const bump = data[1];
  const currentRoot = bytes32ToBigint(data.subarray(8, 40));
  const nextIndex = data.readBigUInt64LE(40);

  // frontier at offset 48, size 32*20 = 640 bytes
  const frontier: bigint[] = [];
  const frontierOffset = 48;
  for (let i = 0; i < TREE_DEPTH; i++) {
    const start = frontierOffset + i * 32;
    frontier.push(bytes32ToBigint(data.subarray(start, start + 32)));
  }

  return { bump, currentRoot, nextIndex, frontier };
}

// =============================================================================
// ZERO_HASHES (must match on-chain values)
// =============================================================================

// Pre-computed Poseidon zero hashes for empty subtrees
// ZERO_HASHES[0] = 0 (empty leaf)
// ZERO_HASHES[i] = Poseidon(ZERO_HASHES[i-1], ZERO_HASHES[i-1])
function computeZeroHashes(): bigint[] {
  const zeroHashes: bigint[] = [0n];
  for (let i = 1; i <= TREE_DEPTH; i++) {
    zeroHashes.push(poseidonHashSync([zeroHashes[i - 1], zeroHashes[i - 1]]));
  }
  return zeroHashes;
}

// =============================================================================
// Merkle Proof Computation
// =============================================================================

/**
 * Compute merkle proof for a leaf at given index using frontier
 *
 * For an incremental Merkle tree:
 * - frontier[level] = the rightmost filled node at that level
 * - When leaf index bit at level is 0 (left child): sibling is ZERO_HASHES[level]
 * - When leaf index bit at level is 1 (right child): sibling is frontier[level]
 */
function computeMerkleProof(
  commitment: bigint,
  leafIndex: number,
  frontier: bigint[],
  zeroHashes: bigint[]
): { siblings: bigint[]; indices: number[]; root: bigint } {
  const siblings: bigint[] = [];
  const indices: number[] = [];

  let current = commitment;
  let idx = leafIndex;

  for (let level = 0; level < TREE_DEPTH; level++) {
    const isRight = (idx & 1) === 1;
    indices.push(isRight ? 1 : 0);

    // Get sibling:
    // - If we're a left child (isRight=false), sibling is the zero hash for this level
    // - If we're a right child (isRight=true), sibling is from frontier
    const sibling = isRight ? frontier[level] : zeroHashes[level];
    siblings.push(sibling);

    // Compute parent hash
    if (isRight) {
      current = poseidonHashSync([sibling, current]);
    } else {
      current = poseidonHashSync([current, sibling]);
    }

    idx = idx >> 1;
  }

  return { siblings, indices, root: current };
}

// =============================================================================
// VK Hash Computation
// =============================================================================

// VK size constants (must match on-chain)
const BBJS_VK_SIZE = 3680;

/**
 * Compute VK hash matching on-chain logic: keccak256 of VK bytes.
 *
 * On-chain (compute_vk_hash): For bb.js format (>= 3680 bytes), hash first 3680 bytes.
 * Uses the SDK's getVerificationKey() to get the raw bb.js VK bytes.
 */
async function computeVkHash(vkBytes: Uint8Array): Promise<Uint8Array> {
  const hashLen = vkBytes.length >= BBJS_VK_SIZE ? BBJS_VK_SIZE : Math.min(vkBytes.length, 1760);
  const hash = keccak_256(vkBytes.slice(0, hashLen));
  return new Uint8Array(hash);
}

// =============================================================================
// ChadBuffer Upload (for large proofs)
// =============================================================================

// ChadBuffer instruction discriminators
const CHADBUFFER_IX = {
  CREATE: 0,
  ASSIGN: 1,
  WRITE: 2,
  CLOSE: 3,
};

// Max data per write tx
// Overhead: signature (64) + msg header (3) + 2 account keys (66) + ix header (4) + disc (1) + u24 offset (3) = 141 bytes
// Using 176 bytes for safety margin: 1232 - 176 = 1056 bytes max
const MAX_DATA_PER_WRITE = 950; // Tx overhead ~207 bytes + priority fee ~25 bytes = ~232 bytes overhead

// Buffer authority size
const AUTHORITY_SIZE = 32;

function createChadBufferCreateIx(
  chadbufferProgramId: PublicKey,
  bufferKeypair: Keypair,
  payer: PublicKey,
  initialData: Uint8Array
): TransactionInstruction {
  const data = Buffer.alloc(1 + initialData.length);
  data[0] = CHADBUFFER_IX.CREATE;
  data.set(initialData, 1);

  // ChadBuffer CREATE expects: payer, buffer (no system program - account created separately)
  return new TransactionInstruction({
    programId: chadbufferProgramId,
    keys: [
      { pubkey: payer, isSigner: true, isWritable: true },
      { pubkey: bufferKeypair.publicKey, isSigner: true, isWritable: true },
    ],
    data,
  });
}

function createChadBufferWriteIx(
  chadbufferProgramId: PublicKey,
  buffer: PublicKey,
  payer: PublicKey,
  offset: number,
  data: Uint8Array
): TransactionInstruction {
  const ixData = Buffer.alloc(4 + data.length);
  ixData[0] = CHADBUFFER_IX.WRITE;
  // u24 offset (little-endian)
  ixData[1] = offset & 0xff;
  ixData[2] = (offset >> 8) & 0xff;
  ixData[3] = (offset >> 16) & 0xff;
  ixData.set(data, 4);

  return new TransactionInstruction({
    programId: chadbufferProgramId,
    keys: [
      { pubkey: payer, isSigner: true, isWritable: true },
      { pubkey: buffer, isSigner: false, isWritable: true },
    ],
    data: ixData,
  });
}

function createChadBufferCloseIx(
  chadbufferProgramId: PublicKey,
  buffer: PublicKey,
  payer: PublicKey
): TransactionInstruction {
  return new TransactionInstruction({
    programId: chadbufferProgramId,
    keys: [
      { pubkey: payer, isSigner: true, isWritable: true },
      { pubkey: buffer, isSigner: false, isWritable: true },
    ],
    data: Buffer.from([CHADBUFFER_IX.CLOSE]),
  });
}

async function uploadProofToBuffer(
  connection: Connection,
  chadbufferProgramId: PublicKey,
  payer: Keypair,
  proof: Uint8Array
): Promise<PublicKey> {
  // Create buffer keypair
  const bufferKeypair = Keypair.generate();
  const bufferSize = AUTHORITY_SIZE + proof.length;

  log(`Creating buffer for ${proof.length} byte proof...`);

  // Calculate rent
  const rentExemption = await connection.getMinimumBalanceForRentExemption(bufferSize);

  // ChadBuffer CREATE:
  // - discriminator (1 byte)
  // - initial data (variable)
  // Combined with SystemProgram.createAccount, we have limited space.
  // Transaction overhead: ~360 bytes (2 signatures @ 128, header, accounts, instructions)
  // Max tx size: 1232 bytes
  // Available for data: 1232 - 360 = ~870 bytes max, use 800 for safety
  const firstChunkSize = Math.min(800, proof.length);
  const firstChunk = proof.slice(0, firstChunkSize);

  // Create account via SystemProgram + Initialize via ChadBuffer CREATE in one tx
  const createAccountIx = SystemProgram.createAccount({
    fromPubkey: payer.publicKey,
    newAccountPubkey: bufferKeypair.publicKey,
    lamports: rentExemption,
    space: bufferSize,
    programId: chadbufferProgramId,
  });

  const initIx = createChadBufferCreateIx(
    chadbufferProgramId,
    bufferKeypair,
    payer.publicKey,
    firstChunk
  );

  // Add priority fee for devnet congestion (1M micro-lamports for fast inclusion)
  const priorityFeeIx = NETWORK === "devnet"
    ? ComputeBudgetProgram.setComputeUnitPrice({ microLamports: 1_000_000 })
    : null;

  const createTx = new Transaction();
  if (priorityFeeIx) createTx.add(priorityFeeIx);
  createTx.add(createAccountIx, initIx);

  await sendAndConfirmTransaction(connection, createTx, [payer, bufferKeypair], {
    commitment: "confirmed",
    skipPreflight: NETWORK === "devnet",
  });
  log(`✓ Buffer created with ${firstChunkSize} bytes: ${bufferKeypair.publicKey.toBase58().slice(0, 16)}...`);

  // Build all remaining chunks
  const chunks: { offset: number; data: Uint8Array }[] = [];
  let currentOffset = firstChunkSize;
  while (currentOffset < proof.length) {
    const chunkSize = Math.min(MAX_DATA_PER_WRITE, proof.length - currentOffset);
    chunks.push({
      offset: currentOffset,
      data: proof.slice(currentOffset, currentOffset + chunkSize),
    });
    currentOffset += chunkSize;
  }

  // Upload chunks in parallel batches (5 at a time to avoid rate limiting)
  const BATCH_SIZE = 5;
  for (let i = 0; i < chunks.length; i += BATCH_SIZE) {
    const batch = chunks.slice(i, i + BATCH_SIZE);

    const promises = batch.map(async (chunk, batchIdx) => {
      const writeIx = createChadBufferWriteIx(
        chadbufferProgramId,
        bufferKeypair.publicKey,
        payer.publicKey,
        AUTHORITY_SIZE + chunk.offset,
        chunk.data
      );

      const writeTx = new Transaction();
      if (priorityFeeIx) writeTx.add(priorityFeeIx);
      writeTx.add(writeIx);

      // Retry logic
      let retries = 3;
      while (retries > 0) {
        try {
          await sendAndConfirmTransaction(connection, writeTx, [payer], {
            commitment: "confirmed",
            skipPreflight: NETWORK === "devnet",
          });
          return;
        } catch (err: any) {
          retries--;
          if (retries === 0) throw err;
          log(`  Chunk ${i + batchIdx + 2} failed, retrying... (${retries} left)`);
          await new Promise((r) => setTimeout(r, 500));
        }
      }
    });

    await Promise.all(promises);
    log(`  Batch ${Math.floor(i / BATCH_SIZE) + 1}: ${batch.length} chunks uploaded`);
  }

  log(`✓ Uploaded ${chunks.length + 1} chunks total (${proof.length} bytes)`);

  return bufferKeypair.publicKey;
}

// =============================================================================
// Build Claim Instruction
// =============================================================================

/**
 * Build claim instruction data (buffer mode - proof in ChadBuffer, verified by prior instruction)
 *
 * On-chain layout after discriminator is stripped:
 *   root(32) + nullifier_hash(32) + amount_sats(8) + recipient(32) + vk_hash(32) = 136 bytes
 *
 * Total with discriminator: 137 bytes
 */
function buildClaimData(
  root: Uint8Array,
  nullifierHash: Uint8Array,
  amountSats: bigint,
  recipient: PublicKey,
  vkHash: Uint8Array
): Uint8Array {
  const totalSize = 1 + 32 + 32 + 8 + 32 + 32; // 137 bytes
  const data = new Uint8Array(totalSize);
  const view = new DataView(data.buffer);
  let offset = 0;

  // Discriminator
  data[offset++] = DISCRIMINATOR.CLAIM;
  // Root
  data.set(root, offset);
  offset += 32;
  // Nullifier hash
  data.set(nullifierHash, offset);
  offset += 32;
  // Amount (little endian)
  view.setBigUint64(offset, amountSats, true);
  offset += 8;
  // Recipient
  data.set(recipient.toBytes(), offset);
  offset += 32;
  // VK hash
  data.set(vkHash, offset);

  return data;
}

/**
 * Build VERIFY_FROM_BUFFER instruction for UltraHonk verifier.
 *
 * Data format: discriminator(1) + public_inputs_count(4 LE) + public_inputs(N×32) + vk_hash(32)
 * Accounts: [proof_buffer, vk_account]
 */
function buildVerifyFromBufferData(
  publicInputs: Uint8Array[],
  vkHash: Uint8Array
): Uint8Array {
  const piCount = publicInputs.length;
  const totalSize = 1 + 4 + piCount * 32 + 32;
  const data = new Uint8Array(totalSize);
  const view = new DataView(data.buffer);
  let offset = 0;

  // Discriminator (3 = VERIFY_FROM_BUFFER)
  data[offset++] = 3;
  // Public inputs count (little endian u32)
  view.setUint32(offset, piCount, true);
  offset += 4;
  // Public inputs (each 32 bytes)
  for (const pi of publicInputs) {
    data.set(pi, offset);
    offset += 32;
  }
  // VK hash
  data.set(vkHash, offset);

  return data;
}

// =============================================================================
// VK Account Initialization (for UltraHonk verifier)
// =============================================================================

/**
 * Initialize a VK account for the UltraHonk verifier program.
 *
 * The VK is 3680 bytes (bb.js format). Since this exceeds single TX size:
 * 1. Create account owned by verifier program via SystemProgram.createAccount
 * 2. Write VK data in chunks via WRITE_VK_CHUNK (discriminator 4)
 *
 * Note: INIT_VK (disc 2) requires the account to be owned by system program,
 * but createAccount already transfers ownership. So we use WRITE_VK_CHUNK directly.
 */
async function initializeVkAccount(
  connection: Connection,
  authority: Keypair,
  verifierProgramId: PublicKey,
  vkBytes: Uint8Array
): Promise<PublicKey> {
  const vkKeypair = Keypair.generate();
  const vkSize = vkBytes.length;

  log(`Creating VK account (${vkSize} bytes)...`);

  // Calculate rent
  const rentExemption = await connection.getMinimumBalanceForRentExemption(vkSize);

  // Create account owned by verifier program
  const createAccountIx = SystemProgram.createAccount({
    fromPubkey: authority.publicKey,
    newAccountPubkey: vkKeypair.publicKey,
    lamports: rentExemption,
    space: vkSize,
    programId: verifierProgramId,
  });

  const priorityFeeIx = NETWORK === "devnet"
    ? ComputeBudgetProgram.setComputeUnitPrice({ microLamports: 1_000_000 })
    : null;

  // Write first chunk in the same TX as createAccount
  const FIRST_CHUNK_SIZE = Math.min(800, vkSize);
  const firstChunk = vkBytes.slice(0, FIRST_CHUNK_SIZE);

  // WRITE_VK_CHUNK data: disc(1) + offset(4 LE) + chunk_data
  const firstWriteData = new Uint8Array(1 + 4 + firstChunk.length);
  firstWriteData[0] = 4; // WRITE_VK_CHUNK discriminator
  // offset = 0 (little-endian u32)
  firstWriteData[1] = 0; firstWriteData[2] = 0; firstWriteData[3] = 0; firstWriteData[4] = 0;
  firstWriteData.set(firstChunk, 5);

  const firstWriteIx = new TransactionInstruction({
    programId: verifierProgramId,
    keys: [
      { pubkey: vkKeypair.publicKey, isWritable: true, isSigner: false },
      { pubkey: authority.publicKey, isWritable: true, isSigner: true },
    ],
    data: Buffer.from(firstWriteData),
  });

  const createTx = new Transaction();
  if (priorityFeeIx) createTx.add(priorityFeeIx);
  createTx.add(createAccountIx, firstWriteIx);

  await sendAndConfirmTransaction(connection, createTx, [authority, vkKeypair], {
    commitment: "confirmed",
    skipPreflight: NETWORK === "devnet",
  });
  log(`✓ VK account created + first ${FIRST_CHUNK_SIZE} bytes written: ${vkKeypair.publicKey.toBase58().slice(0, 16)}...`);

  // Write remaining chunks via WRITE_VK_CHUNK
  let currentOffset = FIRST_CHUNK_SIZE;
  const MAX_CHUNK_SIZE = 950;

  while (currentOffset < vkSize) {
    const chunkSize = Math.min(MAX_CHUNK_SIZE, vkSize - currentOffset);
    const chunk = vkBytes.slice(currentOffset, currentOffset + chunkSize);

    const writeData = new Uint8Array(1 + 4 + chunk.length);
    writeData[0] = 4; // WRITE_VK_CHUNK discriminator
    const offsetView = new DataView(writeData.buffer);
    offsetView.setUint32(1, currentOffset, true);
    writeData.set(chunk, 5);

    const writeIx = new TransactionInstruction({
      programId: verifierProgramId,
      keys: [
        { pubkey: vkKeypair.publicKey, isWritable: true, isSigner: false },
        { pubkey: authority.publicKey, isWritable: true, isSigner: true },
      ],
      data: Buffer.from(writeData),
    });

    const writeTx = new Transaction();
    if (priorityFeeIx) writeTx.add(priorityFeeIx);
    writeTx.add(writeIx);

    await sendAndConfirmTransaction(connection, writeTx, [authority], {
      commitment: "confirmed",
      skipPreflight: NETWORK === "devnet",
    });
    log(`  Wrote VK chunk at offset ${currentOffset}, ${chunkSize} bytes`);
    currentOffset += chunkSize;
  }

  log(`✓ VK account fully initialized (${vkSize} bytes)`);
  return vkKeypair.publicKey;
}

// =============================================================================
// Main Test
// =============================================================================

async function main() {
  console.log("============================================================");
  console.log("Full On-Chain E2E Test - Real Proof Verification");
  console.log("============================================================");

  // Load configs
  if (!fs.existsSync(configPath)) {
    console.error("❌ Localnet config not found. Run deploy-localnet.ts first.");
    process.exit(1);
  }
  const localConfig = JSON.parse(fs.readFileSync(configPath, "utf-8"));
  const mainConfig = JSON.parse(fs.readFileSync(mainConfigPath, "utf-8"));

  // Setup connection
  const connection = new Connection(RPC_URL, "confirmed");
  const walletPath = mainConfig.wallet?.path || "~/.config/solana/id.json";
  const authority = await loadKeypair(walletPath);

  // Program IDs
  const programId = new PublicKey(localConfig.programs.zVault);
  const zkbtcMint = new PublicKey(localConfig.accounts.zkbtcMint);
  const poolVault = new PublicKey(localConfig.accounts.poolVault);

  // UltraHonk verifier - get from config or keypair
  let ultrahonkVerifierId: PublicKey;
  if (localConfig.programs.ultrahonkVerifier) {
    ultrahonkVerifierId = new PublicKey(localConfig.programs.ultrahonkVerifier);
  } else {
    const ultrahonkKeypairPath = path.join(__dirname, "..", "target/deploy/ultrahonk_verifier-keypair.json");
    const ultrahonkKeypair = await loadKeypair(ultrahonkKeypairPath);
    ultrahonkVerifierId = ultrahonkKeypair.publicKey;
  }

  // PDAs
  const [poolStatePda] = derivePoolStatePDA(programId);
  const [commitmentTreePda] = deriveCommitmentTreePDA(programId);

  logSection("Setup");
  log(`Authority: ${authority.publicKey.toBase58()}`);
  log(`Program ID: ${programId.toBase58()}`);
  log(`UltraHonk Verifier: ${ultrahonkVerifierId.toBase58()}`);
  log(`zkBTC Mint: ${zkbtcMint.toBase58()}`);

  // Initialize Poseidon
  await initPoseidon();
  log("✓ Poseidon initialized");

  // Compute zero hashes (needed for merkle proofs)
  const zeroHashes = computeZeroHashes();
  log(`✓ Zero hashes computed (${zeroHashes.length} levels)`);

  // Initialize prover
  const circuitPath = path.resolve(__dirname, "../../sdk/circuits");
  setCircuitPath(circuitPath);
  await initProver();
  log("✓ Prover initialized");

  // ==========================================================================
  // Step 1: Generate ZVault keys (proper stealth model)
  // ==========================================================================
  logSection("Step 1: Generate Stealth Keys");

  // Generate deterministic keys from a seed (simulating wallet signature derivation)
  const testSeed = randomFieldElement();
  const keys: ZVaultKeys = await deriveKeysFromSeed(bigintToBytes32(testSeed));

  // Create stealth meta address (spending + viewing public keys)
  const stealthMetaAddress: StealthMetaAddress = createStealthMetaAddress(keys);

  log(`Spending pub X: 0x${keys.spendingPubKey.x.toString(16).slice(0, 16)}...`);
  log(`Viewing pub X: 0x${keys.viewingPubKey.x.toString(16).slice(0, 16)}...`);

  // ==========================================================================
  // Step 2: Create stealth deposit (correct commitment model)
  // ==========================================================================
  logSection("Step 2: Create Stealth Deposit");

  // Use SDK's createStealthDeposit - produces correct commitment: Poseidon(stealthPub.x, amount)
  // where stealthPub.x is an EC point x-coordinate (not a Poseidon hash!)
  const stealthDepositData = await createStealthDeposit(stealthMetaAddress, DEMO_AMOUNT);

  // Extract deposit data
  const ephemeralPub = stealthDepositData.ephemeralPub;
  const commitment = bytesToBigint(stealthDepositData.commitment);
  const commitmentBytes = stealthDepositData.commitment;
  const encryptedAmountBytes = stealthDepositData.encryptedAmount;

  log(`Ephemeral pub: 0x${Buffer.from(ephemeralPub).toString("hex").slice(0, 16)}...`);
  log(`Commitment: 0x${commitment.toString(16).slice(0, 16)}...`);
  log(`Encrypted amount: 0x${Buffer.from(encryptedAmountBytes).toString("hex")}`);

  const [stealthAnnouncementPDA] = deriveStealthAnnouncementPDA(ephemeralPub, programId);

  const demoData = buildAddDemoStealthData(ephemeralPub, commitmentBytes, encryptedAmountBytes);

  const demoIx = new TransactionInstruction({
    programId,
    keys: [
      { pubkey: poolStatePda, isWritable: true, isSigner: false },
      { pubkey: commitmentTreePda, isWritable: true, isSigner: false },
      { pubkey: stealthAnnouncementPDA, isWritable: true, isSigner: false },
      { pubkey: authority.publicKey, isWritable: true, isSigner: true },
      { pubkey: SystemProgram.programId, isWritable: false, isSigner: false },
      { pubkey: zkbtcMint, isWritable: true, isSigner: false },
      { pubkey: poolVault, isWritable: true, isSigner: false },
      { pubkey: TOKEN_2022_PROGRAM_ID, isWritable: false, isSigner: false },
    ],
    data: Buffer.from(demoData),
  });

  const demoTx = new Transaction();
  if (NETWORK === "devnet") {
    demoTx.add(ComputeBudgetProgram.setComputeUnitPrice({ microLamports: 1_000_000 }));
  }
  demoTx.add(demoIx);

  // Retry logic for demo deposit
  let demoSig = "";
  let demoRetries = 3;
  while (demoRetries > 0) {
    try {
      demoSig = await sendAndConfirmTransaction(connection, demoTx, [authority], {
        commitment: "confirmed",
        skipPreflight: NETWORK === "devnet",
      });
      break;
    } catch (err: any) {
      demoRetries--;
      if (demoRetries === 0) throw err;
      log(`  Demo deposit failed, retrying... (${demoRetries} left)`);
      await new Promise((r) => setTimeout(r, 2000));
    }
  }
  log(`✓ Demo deposit: ${demoSig.slice(0, 16)}...`);

  // ==========================================================================
  // Step 3: Fetch on-chain tree state
  // ==========================================================================
  logSection("Step 3: Fetch On-Chain Tree State");

  const treeAccount = await connection.getAccountInfo(commitmentTreePda);
  if (!treeAccount) throw new Error("Commitment tree not found");

  const treeState = parseCommitmentTree(treeAccount.data as Buffer);
  const leafIndex = Number(treeState.nextIndex) - 1;

  log(`Leaf index: ${leafIndex}`);
  log(`On-chain root: 0x${treeState.currentRoot.toString(16).slice(0, 16)}...`);
  log(`Next index: ${treeState.nextIndex}`);

  // ==========================================================================
  // Step 4: Compute merkle proof matching on-chain root
  // ==========================================================================
  logSection("Step 4: Compute Merkle Proof");

  const merkleProof = computeMerkleProof(commitment, leafIndex, treeState.frontier, zeroHashes);

  log(`Computed root: 0x${merkleProof.root.toString(16).slice(0, 16)}...`);
  log(`Root match: ${merkleProof.root === treeState.currentRoot ? "✓ YES" : "❌ NO"}`);

  if (merkleProof.root !== treeState.currentRoot) {
    log("⚠ Root mismatch - using on-chain root for proof");
  }

  // ==========================================================================
  // Step 5: Scan the deposit and derive stealth key
  // ==========================================================================
  logSection("Step 5: Scan Deposit & Derive Keys");

  const leafIndexBigint = BigInt(leafIndex);

  // Use scanAnnouncements to properly reconstruct the ScannedNote
  // This uses the SDK's internal stealth derivation logic (SHA256 domain separator)
  const { scanAnnouncements } = await import("@zvault/sdk");

  // Format the deposit as an announcement for scanning
  const announcements = [{
    ephemeralPub: ephemeralPub,
    encryptedAmount: encryptedAmountBytes,
    commitment: commitmentBytes,
    leafIndex: leafIndex,
  }];

  // Scan using our keys - this derives stealthPub correctly
  const scannedNotes = await scanAnnouncements(keys, announcements);

  if (scannedNotes.length === 0) {
    throw new Error("Failed to scan deposit - commitment mismatch or decryption failed");
  }

  const scannedNote = scannedNotes[0];
  log(`✓ Deposit scanned successfully`);
  log(`  Amount: ${scannedNote.amount.toString()} sats`);
  log(`  StealthPub.x: 0x${scannedNote.stealthPub.x.toString(16).slice(0, 16)}...`);

  // Use SDK's prepareClaimInputs to derive stealthPrivKey correctly
  const claimPrepInputs = await prepareClaimInputs(keys, scannedNote, {
    root: treeState.currentRoot,
    pathElements: merkleProof.siblings,
    pathIndices: merkleProof.indices,
  });

  // Extract stealthPrivKey and pubKeyX from prepared inputs
  const stealthPrivKey = claimPrepInputs.stealthPrivKey;
  const pubKeyX = scannedNote.stealthPub.x;

  log(`Stealth priv: 0x${stealthPrivKey.toString(16).slice(0, 16)}...`);
  log(`Stealth pub X: 0x${pubKeyX.toString(16).slice(0, 16)}...`);

  // Compute nullifier using stealth private key
  const nullifier = computeNullifierSync(stealthPrivKey, leafIndexBigint);
  const nullifierHash = hashNullifierSync(nullifier);
  const nullifierHashBytes = bigintToBytes32(nullifierHash);

  log(`Nullifier: 0x${nullifier.toString(16).slice(0, 16)}...`);
  log(`Nullifier hash: 0x${nullifierHash.toString(16).slice(0, 16)}...`);

  // Verify commitment matches what circuit will compute
  const expectedCommitment = computeUnifiedCommitmentSync(pubKeyX, DEMO_AMOUNT);
  if (expectedCommitment !== commitment) {
    log(`⚠ Commitment mismatch!`);
    log(`  Expected: 0x${expectedCommitment.toString(16).slice(0, 16)}...`);
    log(`  Actual: 0x${commitment.toString(16).slice(0, 16)}...`);
    throw new Error("Commitment verification failed");
  }
  log(`✓ Commitment verified: Poseidon(stealthPub.x, amount)`);

  // ==========================================================================
  // Step 6: Generate ZK proof
  // ==========================================================================
  logSection("Step 6: Generate ZK Proof");

  // Convert recipient (Solana pubkey) to bigint for circuit
  const recipientBigint = bytes32ToBigint(authority.publicKey.toBytes());

  const claimInputs: ClaimInputs = {
    privKey: stealthPrivKey,  // Use stealth private key (not original spending key!)
    pubKeyX,                  // Use stealthPub.x (EC point x-coordinate)
    amount: DEMO_AMOUNT,
    leafIndex: leafIndexBigint,
    merkleRoot: treeState.currentRoot, // Use on-chain root
    merkleProof: {
      siblings: merkleProof.siblings,
      indices: merkleProof.indices,
    },
    recipient: recipientBigint, // Bound to proof - prevents fund redirection
  };

  log("Generating UltraHonk proof...");
  const startTime = Date.now();
  const proofData = await generateClaimProof(claimInputs);
  const duration = ((Date.now() - startTime) / 1000).toFixed(2);

  log(`✓ Proof generated in ${duration}s`);
  log(`Proof size: ${proofData.proof.length} bytes`);
  log(`Public inputs: ${proofData.publicInputs.length}`);

  // ==========================================================================
  // Step 7: Compute VK hash
  // ==========================================================================
  // Step 7: Get VK bytes + Initialize VK Account
  // ==========================================================================
  logSection("Step 7: Initialize Verifier VK Account");

  // Get raw VK bytes from SDK prover (bb.js format, 3680 bytes)
  const vkBytes = await getVerificationKey("claim" as CircuitType);
  const vkHash = await computeVkHash(vkBytes);
  log(`VK size: ${vkBytes.length} bytes`);
  log(`VK hash (keccak256): 0x${Buffer.from(vkHash).toString("hex").slice(0, 32)}...`);

  // Check if VK account already exists (from a previous run)
  // We store the VK account address in localnet config if available
  let vkAccountPubkey: PublicKey;

  if (localConfig.accounts?.ultrahonkVkAccount) {
    vkAccountPubkey = new PublicKey(localConfig.accounts.ultrahonkVkAccount);
    const existing = await connection.getAccountInfo(vkAccountPubkey);
    if (existing && existing.owner.equals(ultrahonkVerifierId)) {
      log(`✓ VK account already initialized: ${vkAccountPubkey.toBase58()}`);
    } else {
      log("VK account not found or not owned by verifier, re-creating...");
      vkAccountPubkey = await initializeVkAccount(
        connection, authority, ultrahonkVerifierId, vkBytes
      );
    }
  } else {
    vkAccountPubkey = await initializeVkAccount(
      connection, authority, ultrahonkVerifierId, vkBytes
    );
    // Save to config for future runs
    localConfig.accounts = localConfig.accounts || {};
    localConfig.accounts.ultrahonkVkAccount = vkAccountPubkey.toBase58();
    fs.writeFileSync(configPath, JSON.stringify(localConfig, null, 2) + "\n");
    log(`Saved VK account to config`);
  }
  log(`VK account: ${vkAccountPubkey.toBase58()}`);

  // ==========================================================================
  // Step 8: Upload Proof to ChadBuffer
  // ==========================================================================
  logSection("Step 8: Upload Proof to ChadBuffer");

  // Get ChadBuffer program ID from config
  const chadbufferProgramId = new PublicKey(localConfig.programs.chadbuffer);
  log(`ChadBuffer Program: ${chadbufferProgramId.toBase58()}`);
  log(`Proof size: ${proofData.proof.length} bytes`);

  // Upload proof to buffer
  const proofBuffer = await uploadProofToBuffer(
    connection,
    chadbufferProgramId,
    authority,
    proofData.proof
  );
  log(`✓ Proof buffer: ${proofBuffer.toBase58()}`);

  // ==========================================================================
  // Step 9: Submit On-Chain Claim (Verify + Claim in one TX)
  // ==========================================================================
  logSection("Step 9: Submit On-Chain Claim");

  // Create recipient ATA if needed
  const recipientAta = getAssociatedTokenAddressSync(
    zkbtcMint,
    authority.publicKey,
    false,
    TOKEN_2022_PROGRAM_ID
  );

  try {
    await getAccount(connection, recipientAta, "confirmed", TOKEN_2022_PROGRAM_ID);
    log(`Recipient ATA exists: ${recipientAta.toBase58()}`);
  } catch {
    log("Creating recipient ATA...");
    const createAtaIx = createAssociatedTokenAccountInstruction(
      authority.publicKey,
      recipientAta,
      authority.publicKey,
      zkbtcMint,
      TOKEN_2022_PROGRAM_ID
    );
    const ataTx = new Transaction();
    if (NETWORK === "devnet") {
      ataTx.add(ComputeBudgetProgram.setComputeUnitPrice({ microLamports: 1_000_000 }));
    }
    ataTx.add(createAtaIx);
    await sendAndConfirmTransaction(connection, ataTx, [authority], { commitment: "confirmed" });
    log(`✓ Created: ${recipientAta.toBase58()}`);
  }

  // Derive nullifier PDA
  const [nullifierPda] = deriveNullifierPDA(nullifierHashBytes, programId);

  // --- Build VERIFY_FROM_BUFFER instruction (must precede claim) ---
  // Convert proof public inputs to 32-byte arrays
  const publicInputArrays: Uint8Array[] = proofData.publicInputs.map((pi: string) => {
    const bigVal = BigInt(pi);
    return bigintToBytes32(bigVal);
  });

  const verifyData = buildVerifyFromBufferData(publicInputArrays, vkHash);
  const verifyIx = new TransactionInstruction({
    programId: ultrahonkVerifierId,
    keys: [
      { pubkey: proofBuffer, isWritable: false, isSigner: false },       // 0: proof_buffer
      { pubkey: vkAccountPubkey, isWritable: false, isSigner: false },   // 1: vk_account
    ],
    data: Buffer.from(verifyData),
  });
  log(`VERIFY_FROM_BUFFER ix: ${verifyData.length} bytes, ${publicInputArrays.length} public inputs`);

  // --- Build claim instruction ---
  const claimData = buildClaimData(
    bigintToBytes32(treeState.currentRoot),
    nullifierHashBytes,
    DEMO_AMOUNT,
    authority.publicKey,
    vkHash
  );

  // Instructions sysvar for introspection
  const INSTRUCTIONS_SYSVAR = new PublicKey("Sysvar1nstructions1111111111111111111111111");

  // Account order: pool_state, commitment_tree, nullifier, zbtc_mint, pool_vault,
  //   recipient_ata, user, token_program, system_program, ultrahonk_verifier,
  //   proof_buffer, instructions_sysvar
  const claimIx = new TransactionInstruction({
    programId,
    keys: [
      { pubkey: poolStatePda, isWritable: true, isSigner: false },         // 0: pool_state
      { pubkey: commitmentTreePda, isWritable: false, isSigner: false },   // 1: commitment_tree
      { pubkey: nullifierPda, isWritable: true, isSigner: false },         // 2: nullifier_record
      { pubkey: zkbtcMint, isWritable: true, isSigner: false },            // 3: zbtc_mint
      { pubkey: poolVault, isWritable: true, isSigner: false },            // 4: pool_vault
      { pubkey: recipientAta, isWritable: true, isSigner: false },         // 5: recipient_ata
      { pubkey: authority.publicKey, isWritable: true, isSigner: true },   // 6: user (signer)
      { pubkey: TOKEN_2022_PROGRAM_ID, isWritable: false, isSigner: false }, // 7: token_program
      { pubkey: SystemProgram.programId, isWritable: false, isSigner: false }, // 8: system_program
      { pubkey: ultrahonkVerifierId, isWritable: false, isSigner: false }, // 9: ultrahonk_verifier
      { pubkey: proofBuffer, isWritable: false, isSigner: false },         // 10: proof_buffer
      { pubkey: INSTRUCTIONS_SYSVAR, isWritable: false, isSigner: false }, // 11: instructions_sysvar
    ],
    data: Buffer.from(claimData),
  });

  // Add compute budget and priority fee
  const computeIx = ComputeBudgetProgram.setComputeUnitLimit({ units: 1_400_000 });
  const claimPriorityIx = NETWORK === "devnet"
    ? ComputeBudgetProgram.setComputeUnitPrice({ microLamports: 1_000_000 })
    : null;

  // Transaction: [compute_budget] + [priority_fee?] + [VERIFY_FROM_BUFFER] + [claim]
  const claimTx = new Transaction();
  if (claimPriorityIx) claimTx.add(claimPriorityIx);
  claimTx.add(computeIx, verifyIx, claimIx);

  log(`Claim data: ${claimData.length} bytes`);
  log(`Nullifier PDA: ${nullifierPda.toBase58()}`);
  log(`Proof buffer: ${proofBuffer.toBase58()}`);
  log(`VK account: ${vkAccountPubkey.toBase58()}`);
  log("Submitting [VERIFY_FROM_BUFFER + CLAIM] transaction...");

  try {
    // Simulate first
    const { value: simResult } = await connection.simulateTransaction(claimTx, [authority]);

    if (simResult.err) {
      log(`❌ Simulation failed: ${JSON.stringify(simResult.err)}`);
      if (simResult.logs) {
        log("Logs:");
        simResult.logs.forEach((l) => console.log(`    ${l}`));
      }
    } else {
      log(`✓ Simulation passed! CU: ${simResult.unitsConsumed}`);

      // Send real transaction
      const sig = await sendAndConfirmTransaction(connection, claimTx, [authority], {
        commitment: "confirmed",
      });
      log(`✓ Claim successful! Signature: ${sig}`);

      // Check balance
      const ataAccount = await getAccount(connection, recipientAta, "confirmed", TOKEN_2022_PROGRAM_ID);
      log(`✓ Recipient balance: ${ataAccount.amount} sats`);
    }
  } catch (err: any) {
    log(`❌ Error: ${err.message}`);
    if (err.logs) {
      log("Logs:");
      err.logs.forEach((l: string) => console.log(`    ${l}`));
    }
  }

  // ==========================================================================
  // Step 10: Close Proof Buffer (reclaim rent)
  // ==========================================================================
  logSection("Step 10: Close Proof Buffer");

  try {
    const closeIx = createChadBufferCloseIx(chadbufferProgramId, proofBuffer, authority.publicKey);
    const closeTx = new Transaction();
    if (NETWORK === "devnet") {
      closeTx.add(ComputeBudgetProgram.setComputeUnitPrice({ microLamports: 1_000_000 }));
    }
    closeTx.add(closeIx);
    const closeSig = await sendAndConfirmTransaction(connection, closeTx, [authority], {
      commitment: "confirmed",
    });
    log(`✓ Buffer closed, rent reclaimed: ${closeSig.slice(0, 16)}...`);
  } catch (err: any) {
    log(`⚠ Failed to close buffer: ${err.message}`);
  }

  // Cleanup
  logSection("Cleanup");
  await cleanupProver();
  log("✓ Prover resources released");

  console.log("\n============================================================");
  console.log("E2E Test Complete");
  console.log("============================================================\n");
}

main().catch((err) => {
  console.error("Fatal error:", err);
  process.exit(1);
});
