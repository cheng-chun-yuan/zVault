{"noir_version":"1.0.0-beta.18+99bb8b5cf33d7669adbdef096b12d80f30b4c0c9","hash":"5989701948259473939","abi":{"parameters":[{"name":"old_priv_key","type":{"kind":"field"},"visibility":"private"},{"name":"old_pub_key_x","type":{"kind":"field"},"visibility":"private"},{"name":"principal","type":{"kind":"integer","sign":"unsigned","width":64},"visibility":"private"},{"name":"deposit_epoch","type":{"kind":"integer","sign":"unsigned","width":64},"visibility":"private"},{"name":"leaf_index","type":{"kind":"field"},"visibility":"private"},{"name":"pool_merkle_path","type":{"kind":"array","length":20,"type":{"kind":"field"}},"visibility":"private"},{"name":"pool_path_indices","type":{"kind":"array","length":20,"type":{"kind":"integer","sign":"unsigned","width":1}},"visibility":"private"},{"name":"new_pub_key_x","type":{"kind":"field"},"visibility":"private"},{"name":"yield_pub_key_x","type":{"kind":"field"},"visibility":"private"},{"name":"pool_merkle_root","type":{"kind":"field"},"visibility":"public"},{"name":"old_nullifier_hash","type":{"kind":"field"},"visibility":"public"},{"name":"new_pool_commitment","type":{"kind":"field"},"visibility":"public"},{"name":"yield_commitment","type":{"kind":"field"},"visibility":"public"},{"name":"current_epoch","type":{"kind":"integer","sign":"unsigned","width":64},"visibility":"public"},{"name":"yield_rate_bps","type":{"kind":"integer","sign":"unsigned","width":64},"visibility":"public"},{"name":"pool_id","type":{"kind":"field"},"visibility":"public"}],"return_type":null,"error_types":{"361444214588792908":{"error_kind":"string","string":"attempt to multiply with overflow"},"1487477408645045844":{"error_kind":"string","string":"Old private key cannot be zero"},"1998584279744703196":{"error_kind":"string","string":"attempt to subtract with overflow"},"2664618233293886621":{"error_kind":"string","string":"New pool key must differ from old"},"4529751815805662375":{"error_kind":"string","string":"Old pool position not in Merkle tree"},"4599518994154635049":{"error_kind":"string","string":"New pool commitment mismatch"},"5946426926771771018":{"error_kind":"string","string":"Invalid old nullifier hash"},"6754697234922975557":{"error_kind":"string","string":"Yield public key cannot be zero"},"9464391363628691033":{"error_kind":"string","string":"Pool ID cannot be zero"},"10501997288775362879":{"error_kind":"string","string":"Current epoch must be >= deposit epoch"},"10910463877680669182":{"error_kind":"string","string":"Yield commitment mismatch"},"16124094636063744221":{"error_kind":"string","string":"New pool public key cannot be zero"}}},"bytecode":"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","debug_symbols":"rZnRbiM3DEX/xc95EEVKpPZXiiJwEmdhwHACr71AEey/V4xJOS4qdTraJ914omOKw0tpxh+bl93T5fvj/vj69mPz7Y+PzdNpfzjsvz8e3p635/3bsX768eth438+nk+7Xf1o8+V6nfW+Pe2O58234+VweNj83B4un//04317/BzP21O9Gh42u+NLHSvwdX/Yqfr1cJsd+lOhINpsKAkaIOflhAyNILiGIPkWg5QeAQcEpuQECfFGgDsC9QmYogEIcpuf5G5+6s+PUYoBIn6J4B+EPFgDZA8BQNKaGBiyx8AYegQZ5ZHbneDSXUXpE0q7EaVO+v/zIcSWhZC7WQDoI0jAYyBJt0VAWZyGEkoryNhNw6CkYwA3RYTYNQXQqKK43c1YujU9RCBIK0rEVYgU2kISUhfBk9YCmfYWlGlzDaNY5q4I0/ZSB0z5awRYaLBI0wYbZmLeYRHTv9rj3mGRR0UR2q4BxL3ajjJZ27FM1zaG6doeRrGstjFO1zbiZG2PAAtrG9N0bQ8zMV/biO12oHD3QDTawrBtQIDU3T2wTNY2jZaRxU+mMRfsIkZ9Am+5xNgtCprtmMM8FGl5SKvysMxdlKbdRXnaHMTT5hgu5DeYQ88r/2mOEYFuPTeFvIaQpB2sMsgaQhZuNQGrYmCKjZB5liC0jtBOh1zWPPthaCWFAVetogA3AnVjSDL9+Jhmm2UO8w+Q880yj5pl8FyWuG4Zy3pdpulel9Nkzx8BFjbLPN8sh5mYbpYYcrMXwJrXO3hrt/URMq0hRGoGRerGwIOyFKFWlt3HWMZJezJN25PT9Dl9GMUydzFPu4tl0l0jwEJ3SZh21zAT8+7C9uISKaw5BmDC5o20ahPH3O4G5rxqC+bbFszrHM7Nn8jl/jDzZ/1r+7w/3b343kSqSa81EJONWQ9VdWQbxcZyHTHYCDZGG9FGsjHZaDw0HhoPjUfGI+OR8ch4ZDwyHhmPjEfGI+Ml4yXjJeMl4yXjJeMl4yXjJeMl42XjZeNl42XjZeNl42XjZeNl42XjsfHYeGw8Nh4bj43HxmPjsfHYeGI8MZ4YT4wnxhPjifHEeGI8MV4xXjFeMV4xXjFeMV4xXjFeMV4xHoTgAlxEF+iCXCQX2QW7EBdOBieDk8HJ4GRwMjgZnAxOBieDk6OTo5Ojk6OTo5Ojk9064N4BNY9u2qDu0TcJoPYhUQEuKjkFFZWcQAW5qGTdLkFNdBXsQlxUcqq9D9RIV1HJSb9UrXQVStZ41ExXoWSNR+10FexCXBQTaqmrqOSsMaupWGNWV4mGqrYS/Xb1lfYgUGNdRSWLfqla6yoqWRSo5rqKStbHMFB7fT5K/tye9tunw85+nXu9HJ+//Fh3/uvdr/jPee+nt+fdy+W00/72ea12vL8B","file_map":{"19":{"source":"// Exposed only for usage in `std::meta`\npub(crate) mod poseidon2;\n\nuse crate::default::Default;\nuse crate::embedded_curve_ops::{\n    EmbeddedCurvePoint, EmbeddedCurveScalar, multi_scalar_mul, multi_scalar_mul_array_return,\n};\nuse crate::meta::derive_via;\n\n#[foreign(sha256_compression)]\n// docs:start:sha256_compression\npub fn sha256_compression(input: [u32; 16], state: [u32; 8]) -> [u32; 8] {}\n// docs:end:sha256_compression\n\n#[foreign(keccakf1600)]\n// docs:start:keccakf1600\npub fn keccakf1600(input: [u64; 25]) -> [u64; 25] {}\n// docs:end:keccakf1600\n\npub mod keccak {\n    #[deprecated(\"This function has been moved to std::hash::keccakf1600\")]\n    pub fn keccakf1600(input: [u64; 25]) -> [u64; 25] {\n        super::keccakf1600(input)\n    }\n}\n\n#[foreign(blake2s)]\n// docs:start:blake2s\npub fn blake2s<let N: u32>(input: [u8; N]) -> [u8; 32]\n// docs:end:blake2s\n{}\n\n// docs:start:blake3\npub fn blake3<let N: u32>(input: [u8; N]) -> [u8; 32]\n// docs:end:blake3\n{\n    if crate::runtime::is_unconstrained() {\n        // Temporary measure while Barretenberg is main proving system.\n        // Please open an issue if you're working on another proving system and running into problems due to this.\n        crate::static_assert(\n            N <= 1024,\n            \"Barretenberg cannot prove blake3 hashes with inputs larger than 1024 bytes\",\n        );\n    }\n    __blake3(input)\n}\n\n#[foreign(blake3)]\nfn __blake3<let N: u32>(input: [u8; N]) -> [u8; 32] {}\n\n// docs:start:pedersen_commitment\npub fn pedersen_commitment<let N: u32>(input: [Field; N]) -> EmbeddedCurvePoint {\n    // docs:end:pedersen_commitment\n    pedersen_commitment_with_separator(input, 0)\n}\n\n#[inline_always]\npub fn pedersen_commitment_with_separator<let N: u32>(\n    input: [Field; N],\n    separator: u32,\n) -> EmbeddedCurvePoint {\n    let mut points = [EmbeddedCurveScalar { lo: 0, hi: 0 }; N];\n    for i in 0..N {\n        // we use the unsafe version because the multi_scalar_mul will constrain the scalars.\n        points[i] = from_field_unsafe(input[i]);\n    }\n    let generators = derive_generators(\"DEFAULT_DOMAIN_SEPARATOR\".as_bytes(), separator);\n    multi_scalar_mul(generators, points)\n}\n\n// docs:start:pedersen_hash\npub fn pedersen_hash<let N: u32>(input: [Field; N]) -> Field\n// docs:end:pedersen_hash\n{\n    pedersen_hash_with_separator(input, 0)\n}\n\n#[no_predicates]\npub fn pedersen_hash_with_separator<let N: u32>(input: [Field; N], separator: u32) -> Field {\n    let mut scalars: [EmbeddedCurveScalar; N + 1] = [EmbeddedCurveScalar { lo: 0, hi: 0 }; N + 1];\n    let mut generators: [EmbeddedCurvePoint; N + 1] =\n        [EmbeddedCurvePoint::point_at_infinity(); N + 1];\n    let domain_generators: [EmbeddedCurvePoint; N] =\n        derive_generators(\"DEFAULT_DOMAIN_SEPARATOR\".as_bytes(), separator);\n\n    for i in 0..N {\n        scalars[i] = from_field_unsafe(input[i]);\n        generators[i] = domain_generators[i];\n    }\n    scalars[N] = EmbeddedCurveScalar { lo: N as Field, hi: 0 as Field };\n\n    let length_generator: [EmbeddedCurvePoint; 1] =\n        derive_generators(\"pedersen_hash_length\".as_bytes(), 0);\n    generators[N] = length_generator[0];\n    multi_scalar_mul_array_return(generators, scalars, true)[0].x\n}\n\n#[field(bn254)]\n#[inline_always]\npub fn derive_generators<let N: u32, let M: u32>(\n    domain_separator_bytes: [u8; M],\n    starting_index: u32,\n) -> [EmbeddedCurvePoint; N] {\n    crate::assert_constant(domain_separator_bytes);\n    // TODO(https://github.com/noir-lang/noir/issues/5672): Add back assert_constant on starting_index\n    __derive_generators(domain_separator_bytes, starting_index)\n}\n\n#[builtin(derive_pedersen_generators)]\n#[field(bn254)]\nfn __derive_generators<let N: u32, let M: u32>(\n    domain_separator_bytes: [u8; M],\n    starting_index: u32,\n) -> [EmbeddedCurvePoint; N] {}\n\n#[field(bn254)]\n// Decompose the input 'bn254 scalar' into two 128 bits limbs.\n// It is called 'unsafe' because it does not assert the limbs are 128 bits\n// Assuming the limbs are 128 bits:\n// Assert the decomposition does not overflow the field size.\nfn from_field_unsafe(scalar: Field) -> EmbeddedCurveScalar {\n    // Safety: xlo and xhi decomposition is checked below\n    let (xlo, xhi) = unsafe { crate::field::bn254::decompose_hint(scalar) };\n    // Check that the decomposition is correct\n    assert_eq(scalar, xlo + crate::field::bn254::TWO_POW_128 * xhi);\n    // Check that the decomposition does not overflow the field size\n    let (a, b) = if xhi == crate::field::bn254::PHI {\n        (xlo, crate::field::bn254::PLO)\n    } else {\n        (xhi, crate::field::bn254::PHI)\n    };\n    crate::field::bn254::assert_lt(a, b);\n\n    EmbeddedCurveScalar { lo: xlo, hi: xhi }\n}\n\npub fn poseidon2_permutation<let N: u32>(input: [Field; N], state_len: u32) -> [Field; N] {\n    assert_eq(input.len(), state_len);\n    poseidon2_permutation_internal(input)\n}\n\n#[foreign(poseidon2_permutation)]\nfn poseidon2_permutation_internal<let N: u32>(input: [Field; N]) -> [Field; N] {}\n\n// Generic hashing support.\n// Partially ported and impacted by rust.\n\n// Hash trait shall be implemented per type.\n#[derive_via(derive_hash)]\npub trait Hash {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher;\n}\n\n// docs:start:derive_hash\ncomptime fn derive_hash(s: TypeDefinition) -> Quoted {\n    let name = quote { $crate::hash::Hash };\n    let signature = quote { fn hash<H>(_self: Self, _state: &mut H) where H: $crate::hash::Hasher };\n    let for_each_field = |name| quote { _self.$name.hash(_state); };\n    crate::meta::make_trait_impl(\n        s,\n        name,\n        signature,\n        for_each_field,\n        quote {},\n        |fields| fields,\n    )\n}\n// docs:end:derive_hash\n\n// Hasher trait shall be implemented by algorithms to provide hash-agnostic means.\n// TODO: consider making the types generic here ([u8], [Field], etc.)\npub trait Hasher {\n    fn finish(self) -> Field;\n\n    fn write(&mut self, input: Field);\n}\n\n// BuildHasher is a factory trait, responsible for production of specific Hasher.\npub trait BuildHasher {\n    type H: Hasher;\n\n    fn build_hasher(self) -> H;\n}\n\npub struct BuildHasherDefault<H>;\n\nimpl<H> BuildHasher for BuildHasherDefault<H>\nwhere\n    H: Hasher + Default,\n{\n    type H = H;\n\n    fn build_hasher(_self: Self) -> H {\n        H::default()\n    }\n}\n\nimpl<H> Default for BuildHasherDefault<H>\nwhere\n    H: Hasher + Default,\n{\n    fn default() -> Self {\n        BuildHasherDefault {}\n    }\n}\n\nimpl Hash for Field {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self);\n    }\n}\n\nimpl Hash for u1 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u8 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u16 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u32 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u64 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u128 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for i8 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as u8 as Field);\n    }\n}\n\nimpl Hash for i16 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as u16 as Field);\n    }\n}\n\nimpl Hash for i32 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as u32 as Field);\n    }\n}\n\nimpl Hash for i64 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as u64 as Field);\n    }\n}\n\nimpl Hash for bool {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for () {\n    fn hash<H>(_self: Self, _state: &mut H)\n    where\n        H: Hasher,\n    {}\n}\n\nimpl<T, let N: u32> Hash for [T; N]\nwhere\n    T: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        for elem in self {\n            elem.hash(state);\n        }\n    }\n}\n\nimpl<T> Hash for [T]\nwhere\n    T: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.len().hash(state);\n        for elem in self {\n            elem.hash(state);\n        }\n    }\n}\n\nimpl<A, B> Hash for (A, B)\nwhere\n    A: Hash,\n    B: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.0.hash(state);\n        self.1.hash(state);\n    }\n}\n\nimpl<A, B, C> Hash for (A, B, C)\nwhere\n    A: Hash,\n    B: Hash,\n    C: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.0.hash(state);\n        self.1.hash(state);\n        self.2.hash(state);\n    }\n}\n\nimpl<A, B, C, D> Hash for (A, B, C, D)\nwhere\n    A: Hash,\n    B: Hash,\n    C: Hash,\n    D: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.0.hash(state);\n        self.1.hash(state);\n        self.2.hash(state);\n        self.3.hash(state);\n    }\n}\n\nimpl<A, B, C, D, E> Hash for (A, B, C, D, E)\nwhere\n    A: Hash,\n    B: Hash,\n    C: Hash,\n    D: Hash,\n    E: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.0.hash(state);\n        self.1.hash(state);\n        self.2.hash(state);\n        self.3.hash(state);\n        self.4.hash(state);\n    }\n}\n\n// Some test vectors for Pedersen hash and Pedersen Commitment.\n// They have been generated using the same functions so the tests are for now useless\n// but they will be useful when we switch to Noir implementation.\n#[test]\nfn assert_pedersen() {\n    assert_eq(\n        pedersen_hash_with_separator([1], 1),\n        0x1b3f4b1a83092a13d8d1a59f7acb62aba15e7002f4440f2275edb99ebbc2305f,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1], 1),\n        EmbeddedCurvePoint {\n            x: 0x054aa86a73cb8a34525e5bbed6e43ba1198e860f5f3950268f71df4591bde402,\n            y: 0x209dcfbf2cfb57f9f6046f44d71ac6faf87254afc7407c04eb621a6287cac126,\n            is_infinite: false,\n        },\n    );\n\n    assert_eq(\n        pedersen_hash_with_separator([1, 2], 2),\n        0x26691c129448e9ace0c66d11f0a16d9014a9e8498ee78f4d69f0083168188255,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2], 2),\n        EmbeddedCurvePoint {\n            x: 0x2e2b3b191e49541fe468ec6877721d445dcaffe41728df0a0eafeb15e87b0753,\n            y: 0x2ff4482400ad3a6228be17a2af33e2bcdf41be04795f9782bd96efe7e24f8778,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3], 3),\n        0x0bc694b7a1f8d10d2d8987d07433f26bd616a2d351bc79a3c540d85b6206dbe4,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3], 3),\n        EmbeddedCurvePoint {\n            x: 0x1fee4e8cf8d2f527caa2684236b07c4b1bad7342c01b0f75e9a877a71827dc85,\n            y: 0x2f9fedb9a090697ab69bf04c8bc15f7385b3e4b68c849c1536e5ae15ff138fd1,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4], 4),\n        0xdae10fb32a8408521803905981a2b300d6a35e40e798743e9322b223a5eddc,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4], 4),\n        EmbeddedCurvePoint {\n            x: 0x07ae3e202811e1fca39c2d81eabe6f79183978e6f12be0d3b8eda095b79bdbc9,\n            y: 0x0afc6f892593db6fbba60f2da558517e279e0ae04f95758587760ba193145014,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5], 5),\n        0xfc375b062c4f4f0150f7100dfb8d9b72a6d28582dd9512390b0497cdad9c22,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5], 5),\n        EmbeddedCurvePoint {\n            x: 0x1754b12bd475a6984a1094b5109eeca9838f4f81ac89c5f0a41dbce53189bb29,\n            y: 0x2da030e3cfcdc7ddad80eaf2599df6692cae0717d4e9f7bfbee8d073d5d278f7,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6], 6),\n        0x1696ed13dc2730062a98ac9d8f9de0661bb98829c7582f699d0273b18c86a572,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6], 6),\n        EmbeddedCurvePoint {\n            x: 0x190f6c0e97ad83e1e28da22a98aae156da083c5a4100e929b77e750d3106a697,\n            y: 0x1f4b60f34ef91221a0b49756fa0705da93311a61af73d37a0c458877706616fb,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7], 7),\n        0x128c0ff144fc66b6cb60eeac8a38e23da52992fc427b92397a7dffd71c45ede3,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7], 7),\n        EmbeddedCurvePoint {\n            x: 0x015441e9d29491b06563fac16fc76abf7a9534c715421d0de85d20dbe2965939,\n            y: 0x1d2575b0276f4e9087e6e07c2cb75aa1baafad127af4be5918ef8a2ef2fea8fc,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7, 8], 8),\n        0x2f960e117482044dfc99d12fece2ef6862fba9242be4846c7c9a3e854325a55c,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7, 8], 8),\n        EmbeddedCurvePoint {\n            x: 0x1657737676968887fceb6dd516382ea13b3a2c557f509811cd86d5d1199bc443,\n            y: 0x1f39f0cb569040105fa1e2f156521e8b8e08261e635a2b210bdc94e8d6d65f77,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9], 9),\n        0x0c96db0790602dcb166cc4699e2d306c479a76926b81c2cb2aaa92d249ec7be7,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9], 9),\n        EmbeddedCurvePoint {\n            x: 0x0a3ceae42d14914a432aa60ec7fded4af7dad7dd4acdbf2908452675ec67e06d,\n            y: 0xfc19761eaaf621ad4aec9a8b2e84a4eceffdba78f60f8b9391b0bd9345a2f2,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 10),\n        0x2cd37505871bc460a62ea1e63c7fe51149df5d0801302cf1cbc48beb8dff7e94,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 10),\n        EmbeddedCurvePoint {\n            x: 0x2fb3f8b3d41ddde007c8c3c62550f9a9380ee546fcc639ffbb3fd30c8d8de30c,\n            y: 0x300783be23c446b11a4c0fabf6c91af148937cea15fcf5fb054abf7f752ee245,\n            is_infinite: false,\n        },\n    );\n}\n","path":"std/hash/mod.nr"},"58":{"source":"use std::default::Default;\nuse std::hash::Hasher;\n\ncomptime global RATE: u32 = 3;\n\npub struct Poseidon2 {\n    cache: [Field; 3],\n    state: [Field; 4],\n    cache_size: u32,\n    squeeze_mode: bool, // 0 => absorb, 1 => squeeze\n}\n\nimpl Poseidon2 {\n    #[no_predicates]\n    pub fn hash<let N: u32>(input: [Field; N], message_size: u32) -> Field {\n        Poseidon2::hash_internal(input, message_size, message_size != N)\n    }\n\n    pub(crate) fn new(iv: Field) -> Poseidon2 {\n        let mut result =\n            Poseidon2 { cache: [0; 3], state: [0; 4], cache_size: 0, squeeze_mode: false };\n        result.state[RATE] = iv;\n        result\n    }\n\n    fn perform_duplex(&mut self) {\n        // add the cache into sponge state\n        for i in 0..RATE {\n            // We effectively zero-pad the cache by only adding to the state\n            // cache that is less than the specified `cache_size`\n            if i < self.cache_size {\n                self.state[i] += self.cache[i];\n            }\n        }\n        self.state = crate::poseidon2_permutation(self.state, 4);\n    }\n\n    fn absorb(&mut self, input: Field) {\n        assert(!self.squeeze_mode);\n        if self.cache_size == RATE {\n            // If we're absorbing, and the cache is full, apply the sponge permutation to compress the cache\n            self.perform_duplex();\n            self.cache[0] = input;\n            self.cache_size = 1;\n        } else {\n            // If we're absorbing, and the cache is not full, add the input into the cache\n            self.cache[self.cache_size] = input;\n            self.cache_size += 1;\n        }\n    }\n\n    fn squeeze(&mut self) -> Field {\n        assert(!self.squeeze_mode);\n        // If we're in absorb mode, apply sponge permutation to compress the cache.\n        self.perform_duplex();\n        self.squeeze_mode = true;\n\n        // Pop one item off the top of the permutation and return it.\n        self.state[0]\n    }\n\n    fn hash_internal<let N: u32>(\n        input: [Field; N],\n        in_len: u32,\n        is_variable_length: bool,\n    ) -> Field {\n        let two_pow_64 = 18446744073709551616;\n        let iv: Field = (in_len as Field) * two_pow_64;\n        let mut sponge = Poseidon2::new(iv);\n        for i in 0..input.len() {\n            if i < in_len {\n                sponge.absorb(input[i]);\n            }\n        }\n\n        // In the case where the hash preimage is variable-length, we append `1` to the end of the input, to distinguish\n        // from fixed-length hashes. (the combination of this additional field element + the hash IV ensures\n        // fixed-length and variable-length hashes do not collide)\n        if is_variable_length {\n            sponge.absorb(1);\n        }\n        sponge.squeeze()\n    }\n}\n\npub struct Poseidon2Hasher {\n    _state: [Field],\n}\n\nimpl Hasher for Poseidon2Hasher {\n    fn finish(self) -> Field {\n        let iv: Field = (self._state.len() as Field) * 18446744073709551616; // iv = (self._state.len() << 64)\n        let mut sponge = Poseidon2::new(iv);\n        for i in 0..self._state.len() {\n            sponge.absorb(self._state[i]);\n        }\n        sponge.squeeze()\n    }\n\n    fn write(&mut self, input: Field) {\n        self._state = self._state.push_back(input);\n    }\n}\n\nimpl Default for Poseidon2Hasher {\n    fn default() -> Self {\n        Poseidon2Hasher { _state: &[] }\n    }\n}\n","path":"/Users/chengchunyuan/nargo/github.com/noir-lang/poseidon/v0.1.1/src/poseidon2.nr"},"61":{"source":"// zVault Unified Cryptographic Utilities\n//\n// UNIFIED MODEL: All commitments and nullifiers use the same format\n//\n// Commitment = Poseidon2(pub_key_x, amount)\n// Nullifier  = Poseidon2(priv_key, leaf_index)\n// Nullifier Hash = Poseidon2(nullifier)\n//\n// This applies to:\n// - User balances (stealth addresses)\n// - Claim links (self-addressed with seed-derived keys)\n// - Pool positions (stealth-based)\n\nuse dep::poseidon::poseidon2::Poseidon2;\n\n// Grumpkin ECDH module for key derivation\npub mod grumpkin;\n\n// ============================================================================\n// Unified Commitment System\n// ============================================================================\n\n/// Compute commitment from public key x-coordinate and amount\n/// commitment = Poseidon2(pub_key_x, amount)\npub fn compute_commitment(pub_key_x: Field, amount: Field) -> Field {\n    Poseidon2::hash([pub_key_x, amount], 2)\n}\n\n/// Compute nullifier from private key and leaf index\n/// nullifier = Poseidon2(priv_key, leaf_index)\npub fn compute_nullifier(priv_key: Field, leaf_index: Field) -> Field {\n    Poseidon2::hash([priv_key, leaf_index], 2)\n}\n\n/// Compute nullifier hash for double-spend prevention\n/// nullifier_hash = Poseidon2(nullifier)\npub fn compute_nullifier_hash(nullifier: Field) -> Field {\n    Poseidon2::hash([nullifier], 1)\n}\n\n// ============================================================================\n// Pool Position Commitment\n// ============================================================================\n\n/// Compute pool position commitment\n/// pool_commitment = Poseidon2(pub_key_x, principal, deposit_epoch)\npub fn compute_pool_commitment(pub_key_x: Field, principal: Field, deposit_epoch: Field) -> Field {\n    Poseidon2::hash([pub_key_x, principal, deposit_epoch], 3)\n}\n\n// ============================================================================\n// Merkle Tree Verification (20-level standard)\n// ============================================================================\n\n/// Verify Merkle proof (20-level tree, ~1M leaves)\npub fn verify_merkle_proof_20(\n    leaf: Field,\n    root: Field,\n    path_elements: [Field; 20],\n    path_indices: [u1; 20],\n) -> bool {\n    let mut current = leaf;\n\n    for i in 0..20 {\n        let sibling = path_elements[i];\n        let is_right = (path_indices[i] == 1) as bool;\n\n        let (left, right) = if is_right {\n            (sibling, current)\n        } else {\n            (current, sibling)\n        };\n\n        current = Poseidon2::hash([left, right], 2);\n    }\n\n    current == root\n}\n\n// ============================================================================\n// Legacy Compatibility (to be removed)\n// ============================================================================\n\n/// Legacy: Compute note from nullifier and secret (OLD FORMAT - deprecated)\npub fn compute_note(nullifier: Field, secret: Field) -> Field {\n    Poseidon2::hash([nullifier, secret], 2)\n}\n\n/// Legacy: Compute commitment from secrets (OLD FORMAT - deprecated)\npub fn compute_commitment_from_secrets(nullifier: Field, secret: Field, amount: Field) -> Field {\n    let note = compute_note(nullifier, secret);\n    Poseidon2::hash([note, amount], 2)\n}\n\n/// Legacy stealth commitment (same as unified - kept for compatibility)\npub fn compute_stealth_commitment(pub_key_x: Field, amount: Field) -> Field {\n    compute_commitment(pub_key_x, amount)\n}\n\n/// Legacy stealth nullifier (same as unified - kept for compatibility)\npub fn compute_stealth_nullifier(priv_key: Field, leaf_index: Field) -> Field {\n    compute_nullifier(priv_key, leaf_index)\n}\n\n/// Legacy stealth nullifier hash (same as unified - kept for compatibility)\npub fn compute_stealth_nullifier_hash(nullifier: Field) -> Field {\n    compute_nullifier_hash(nullifier)\n}\n","path":"/Users/chengchunyuan/project/hackathon/zVault/noir-circuits/utils/src/lib.nr"},"66":{"source":"// Pool Claim Yield Circuit (Unified Model)\n//\n// Proves ownership of pool position and claims earned yield while keeping principal staked.\n// Input:  Pool Position = Poseidon2(pub_key_x, principal, deposit_epoch)\n// Output: 1. New Pool Position = Poseidon2(new_pub_key_x, principal, current_epoch)\n//         2. Yield as Unified Commitment = Poseidon2(yield_pub_key_x, yield_amount)\n//\n// Unified Model:\n//   Commitment = Poseidon2(pub_key_x, amount)\n//   Nullifier  = Poseidon2(priv_key, leaf_index)\n//   Pool Position = Poseidon2(pub_key_x, principal, deposit_epoch)\n\nuse dep::zvault_utils;\n\nfn main(\n    // Private inputs - old pool position\n    old_priv_key: Field,               // Private key for old pool position\n    old_pub_key_x: Field,              // Public key x-coordinate for old position\n    principal: u64,\n    deposit_epoch: u64,\n    leaf_index: Field,                 // Position in merkle tree\n    pool_merkle_path: [Field; 20],\n    pool_path_indices: [u1; 20],\n\n    // Private inputs - new pool position key\n    new_pub_key_x: Field,              // Public key for new pool position\n\n    // Private inputs - yield output key\n    yield_pub_key_x: Field,            // Public key for yield commitment\n\n    // Public inputs\n    pool_merkle_root: pub Field,           // Pool commitment tree root\n    old_nullifier_hash: pub Field,         // Poseidon2(Poseidon2(old_priv_key, leaf_index))\n    new_pool_commitment: pub Field,        // New pool position (same principal, reset epoch)\n    yield_commitment: pub Field,           // Unified commitment for earned yield\n    current_epoch: pub u64,                // Current epoch\n    yield_rate_bps: pub u64,               // Yield rate in basis points\n    pool_id: pub Field,                    // Pool identifier\n) {\n    // 1. Verify old pool position in merkle tree\n    let old_pool_commitment = zvault_utils::compute_pool_commitment(\n        old_pub_key_x,\n        principal as Field,\n        deposit_epoch as Field\n    );\n    assert(\n        zvault_utils::verify_merkle_proof_20(old_pool_commitment, pool_merkle_root, pool_merkle_path, pool_path_indices),\n        \"Old pool position not in Merkle tree\"\n    );\n\n    // 2. Verify old nullifier\n    let old_nullifier = zvault_utils::compute_nullifier(old_priv_key, leaf_index);\n    assert(\n        old_nullifier_hash == zvault_utils::compute_nullifier_hash(old_nullifier),\n        \"Invalid old nullifier hash\"\n    );\n\n    // 3. Security check on old private key\n    assert(old_priv_key != 0, \"Old private key cannot be zero\");\n\n    // 4. Calculate earned yield\n    assert(current_epoch >= deposit_epoch, \"Current epoch must be >= deposit epoch\");\n    let epochs_staked = current_epoch - deposit_epoch;\n    let yield_amount = (principal * epochs_staked * yield_rate_bps) / 10000;\n\n    // 5. Verify new pool position commitment (same principal, reset to current_epoch)\n    let expected_new_commitment = zvault_utils::compute_pool_commitment(\n        new_pub_key_x,\n        principal as Field,\n        current_epoch as Field\n    );\n    assert(\n        new_pool_commitment == expected_new_commitment,\n        \"New pool commitment mismatch\"\n    );\n\n    // 6. Verify yield commitment (unified format)\n    let expected_yield_commitment = zvault_utils::compute_commitment(\n        yield_pub_key_x,\n        yield_amount as Field\n    );\n    assert(\n        yield_commitment == expected_yield_commitment,\n        \"Yield commitment mismatch\"\n    );\n\n    // 7. Ensure new pool key is different from old (for unlinkability)\n    assert(new_pub_key_x != old_pub_key_x, \"New pool key must differ from old\");\n\n    // 8. Security checks\n    assert(new_pub_key_x != 0, \"New pool public key cannot be zero\");\n    assert(yield_pub_key_x != 0, \"Yield public key cannot be zero\");\n    assert(pool_id != 0, \"Pool ID cannot be zero\");\n}\n\n// ============================================================================\n// Tests\n// ============================================================================\n\n#[test]\nfn test_pool_claim_yield_unified_circuit() {\n    // Old pool position keys\n    let old_priv_key = 0x123456789abcdef;\n    let old_pub_key_x = 0xfedcba9876543210;\n\n    // Position details\n    let principal: u64 = 100000000; // 1 BTC\n    let deposit_epoch: u64 = 10;\n    let leaf_index = 0;\n\n    // New pool position key\n    let new_pub_key_x = 0xabcdef012345678;\n\n    // Yield output key\n    let yield_pub_key_x = 0x9876543210abcdef;\n\n    // Current state\n    let current_epoch: u64 = 20; // 10 epochs staked\n    let yield_rate_bps: u64 = 500; // 5% per epoch\n    let pool_id = 1;\n\n    // Calculate yield\n    let epochs_staked = current_epoch - deposit_epoch;\n    let yield_amount = (principal * epochs_staked * yield_rate_bps) / 10000;\n    // yield = 50000000 (0.5 BTC)\n\n    // Compute old pool commitment\n    let old_pool_commitment = zvault_utils::compute_pool_commitment(\n        old_pub_key_x,\n        principal as Field,\n        deposit_epoch as Field\n    );\n\n    // Compute old nullifier\n    let old_nullifier = zvault_utils::compute_nullifier(old_priv_key, leaf_index);\n    let old_nullifier_hash = zvault_utils::compute_nullifier_hash(old_nullifier);\n\n    // Compute new pool commitment (same principal, reset epoch)\n    let new_pool_commitment = zvault_utils::compute_pool_commitment(\n        new_pub_key_x,\n        principal as Field,\n        current_epoch as Field\n    );\n\n    // Compute yield commitment (unified format)\n    let yield_commitment = zvault_utils::compute_commitment(yield_pub_key_x, yield_amount as Field);\n\n    // Build merkle tree\n    let zero: Field = 0;\n    let pool_merkle_path: [Field; 20] = [zero; 20];\n    let pool_path_indices: [u1; 20] = [0; 20];\n\n    let mut current = old_pool_commitment;\n    for _i in 0..20 {\n        current = dep::poseidon::poseidon2::Poseidon2::hash([current, zero], 2);\n    }\n    let pool_merkle_root = current;\n\n    // Run circuit\n    main(\n        old_priv_key,\n        old_pub_key_x,\n        principal,\n        deposit_epoch,\n        leaf_index,\n        pool_merkle_path,\n        pool_path_indices,\n        new_pub_key_x,\n        yield_pub_key_x,\n        pool_merkle_root,\n        old_nullifier_hash,\n        new_pool_commitment,\n        yield_commitment,\n        current_epoch,\n        yield_rate_bps,\n        pool_id\n    );\n}\n\n#[test(should_fail_with = \"New pool key must differ from old\")]\nfn test_pool_claim_yield_same_pool_key() {\n    let old_priv_key = 0x123456789abcdef;\n    let old_pub_key_x = 0xfedcba9876543210;\n\n    let principal: u64 = 100000000;\n    let deposit_epoch: u64 = 10;\n    let leaf_index = 0;\n\n    // INVALID: Same pool key\n    let new_pub_key_x = old_pub_key_x;\n\n    let yield_pub_key_x = 0x9876543210abcdef;\n\n    let current_epoch: u64 = 20;\n    let yield_rate_bps: u64 = 500;\n    let pool_id = 1;\n\n    let epochs_staked = current_epoch - deposit_epoch;\n    let yield_amount = (principal * epochs_staked * yield_rate_bps) / 10000;\n\n    let old_pool_commitment = zvault_utils::compute_pool_commitment(\n        old_pub_key_x,\n        principal as Field,\n        deposit_epoch as Field\n    );\n    let old_nullifier = zvault_utils::compute_nullifier(old_priv_key, leaf_index);\n    let old_nullifier_hash = zvault_utils::compute_nullifier_hash(old_nullifier);\n\n    let new_pool_commitment = zvault_utils::compute_pool_commitment(\n        new_pub_key_x,\n        principal as Field,\n        current_epoch as Field\n    );\n\n    let yield_commitment = zvault_utils::compute_commitment(yield_pub_key_x, yield_amount as Field);\n\n    let zero: Field = 0;\n    let pool_merkle_path: [Field; 20] = [zero; 20];\n    let pool_path_indices: [u1; 20] = [0; 20];\n\n    let mut current = old_pool_commitment;\n    for _i in 0..20 {\n        current = dep::poseidon::poseidon2::Poseidon2::hash([current, zero], 2);\n    }\n    let pool_merkle_root = current;\n\n    main(\n        old_priv_key,\n        old_pub_key_x,\n        principal,\n        deposit_epoch,\n        leaf_index,\n        pool_merkle_path,\n        pool_path_indices,\n        new_pub_key_x,\n        yield_pub_key_x,\n        pool_merkle_root,\n        old_nullifier_hash,\n        new_pool_commitment,\n        yield_commitment,\n        current_epoch,\n        yield_rate_bps,\n        pool_id\n    );\n}\n\n#[test(should_fail_with = \"Old private key cannot be zero\")]\nfn test_pool_claim_yield_zero_priv_key() {\n    let old_priv_key = 0; // INVALID\n    let old_pub_key_x = 0xfedcba9876543210;\n\n    let principal: u64 = 100000000;\n    let deposit_epoch: u64 = 10;\n    let leaf_index = 0;\n\n    let new_pub_key_x = 0xabcdef012345678;\n    let yield_pub_key_x = 0x9876543210abcdef;\n\n    let current_epoch: u64 = 20;\n    let yield_rate_bps: u64 = 500;\n    let pool_id = 1;\n\n    let epochs_staked = current_epoch - deposit_epoch;\n    let yield_amount = (principal * epochs_staked * yield_rate_bps) / 10000;\n\n    let old_pool_commitment = zvault_utils::compute_pool_commitment(\n        old_pub_key_x,\n        principal as Field,\n        deposit_epoch as Field\n    );\n    let old_nullifier = zvault_utils::compute_nullifier(old_priv_key, leaf_index);\n    let old_nullifier_hash = zvault_utils::compute_nullifier_hash(old_nullifier);\n\n    let new_pool_commitment = zvault_utils::compute_pool_commitment(\n        new_pub_key_x,\n        principal as Field,\n        current_epoch as Field\n    );\n\n    let yield_commitment = zvault_utils::compute_commitment(yield_pub_key_x, yield_amount as Field);\n\n    let zero: Field = 0;\n    let pool_merkle_path: [Field; 20] = [zero; 20];\n    let pool_path_indices: [u1; 20] = [0; 20];\n\n    let mut current = old_pool_commitment;\n    for _i in 0..20 {\n        current = dep::poseidon::poseidon2::Poseidon2::hash([current, zero], 2);\n    }\n    let pool_merkle_root = current;\n\n    main(\n        old_priv_key,\n        old_pub_key_x,\n        principal,\n        deposit_epoch,\n        leaf_index,\n        pool_merkle_path,\n        pool_path_indices,\n        new_pub_key_x,\n        yield_pub_key_x,\n        pool_merkle_root,\n        old_nullifier_hash,\n        new_pool_commitment,\n        yield_commitment,\n        current_epoch,\n        yield_rate_bps,\n        pool_id\n    );\n}\n\n#[test(should_fail_with = \"New pool public key cannot be zero\")]\nfn test_pool_claim_yield_zero_new_key() {\n    let old_priv_key = 0x123456789abcdef;\n    let old_pub_key_x = 0xfedcba9876543210;\n\n    let principal: u64 = 100000000;\n    let deposit_epoch: u64 = 10;\n    let leaf_index = 0;\n\n    let new_pub_key_x = 0; // INVALID\n    let yield_pub_key_x = 0x9876543210abcdef;\n\n    let current_epoch: u64 = 20;\n    let yield_rate_bps: u64 = 500;\n    let pool_id = 1;\n\n    let epochs_staked = current_epoch - deposit_epoch;\n    let yield_amount = (principal * epochs_staked * yield_rate_bps) / 10000;\n\n    let old_pool_commitment = zvault_utils::compute_pool_commitment(\n        old_pub_key_x,\n        principal as Field,\n        deposit_epoch as Field\n    );\n    let old_nullifier = zvault_utils::compute_nullifier(old_priv_key, leaf_index);\n    let old_nullifier_hash = zvault_utils::compute_nullifier_hash(old_nullifier);\n\n    let new_pool_commitment = zvault_utils::compute_pool_commitment(\n        new_pub_key_x,\n        principal as Field,\n        current_epoch as Field\n    );\n\n    let yield_commitment = zvault_utils::compute_commitment(yield_pub_key_x, yield_amount as Field);\n\n    let zero: Field = 0;\n    let pool_merkle_path: [Field; 20] = [zero; 20];\n    let pool_path_indices: [u1; 20] = [0; 20];\n\n    let mut current = old_pool_commitment;\n    for _i in 0..20 {\n        current = dep::poseidon::poseidon2::Poseidon2::hash([current, zero], 2);\n    }\n    let pool_merkle_root = current;\n\n    main(\n        old_priv_key,\n        old_pub_key_x,\n        principal,\n        deposit_epoch,\n        leaf_index,\n        pool_merkle_path,\n        pool_path_indices,\n        new_pub_key_x,\n        yield_pub_key_x,\n        pool_merkle_root,\n        old_nullifier_hash,\n        new_pool_commitment,\n        yield_commitment,\n        current_epoch,\n        yield_rate_bps,\n        pool_id\n    );\n}\n\n#[test(should_fail_with = \"Yield public key cannot be zero\")]\nfn test_pool_claim_yield_zero_yield_key() {\n    let old_priv_key = 0x123456789abcdef;\n    let old_pub_key_x = 0xfedcba9876543210;\n\n    let principal: u64 = 100000000;\n    let deposit_epoch: u64 = 10;\n    let leaf_index = 0;\n\n    let new_pub_key_x = 0xabcdef012345678;\n    let yield_pub_key_x = 0; // INVALID\n\n    let current_epoch: u64 = 20;\n    let yield_rate_bps: u64 = 500;\n    let pool_id = 1;\n\n    let epochs_staked = current_epoch - deposit_epoch;\n    let yield_amount = (principal * epochs_staked * yield_rate_bps) / 10000;\n\n    let old_pool_commitment = zvault_utils::compute_pool_commitment(\n        old_pub_key_x,\n        principal as Field,\n        deposit_epoch as Field\n    );\n    let old_nullifier = zvault_utils::compute_nullifier(old_priv_key, leaf_index);\n    let old_nullifier_hash = zvault_utils::compute_nullifier_hash(old_nullifier);\n\n    let new_pool_commitment = zvault_utils::compute_pool_commitment(\n        new_pub_key_x,\n        principal as Field,\n        current_epoch as Field\n    );\n\n    let yield_commitment = zvault_utils::compute_commitment(yield_pub_key_x, yield_amount as Field);\n\n    let zero: Field = 0;\n    let pool_merkle_path: [Field; 20] = [zero; 20];\n    let pool_path_indices: [u1; 20] = [0; 20];\n\n    let mut current = old_pool_commitment;\n    for _i in 0..20 {\n        current = dep::poseidon::poseidon2::Poseidon2::hash([current, zero], 2);\n    }\n    let pool_merkle_root = current;\n\n    main(\n        old_priv_key,\n        old_pub_key_x,\n        principal,\n        deposit_epoch,\n        leaf_index,\n        pool_merkle_path,\n        pool_path_indices,\n        new_pub_key_x,\n        yield_pub_key_x,\n        pool_merkle_root,\n        old_nullifier_hash,\n        new_pool_commitment,\n        yield_commitment,\n        current_epoch,\n        yield_rate_bps,\n        pool_id\n    );\n}\n","path":"/Users/chengchunyuan/project/hackathon/zVault/noir-circuits/pool_claim_yield/src/main.nr"}},"expression_width":{"Bounded":{"width":4}}}