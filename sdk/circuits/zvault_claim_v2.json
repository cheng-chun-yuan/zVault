{"noir_version":"1.0.0-beta.18+99bb8b5cf33d7669adbdef096b12d80f30b4c0c9","hash":"16949582259112716446","abi":{"parameters":[{"name":"spending_priv","type":{"kind":"field"},"visibility":"private"},{"name":"ephemeral_spend_pub_x","type":{"kind":"field"},"visibility":"private"},{"name":"ephemeral_spend_pub_y","type":{"kind":"field"},"visibility":"private"},{"name":"amount","type":{"kind":"field"},"visibility":"private"},{"name":"leaf_index","type":{"kind":"field"},"visibility":"private"},{"name":"merkle_path","type":{"kind":"array","length":20,"type":{"kind":"field"}},"visibility":"private"},{"name":"merkle_indices","type":{"kind":"array","length":20,"type":{"kind":"integer","sign":"unsigned","width":1}},"visibility":"private"},{"name":"merkle_root","type":{"kind":"field"},"visibility":"public"},{"name":"nullifier_pub","type":{"kind":"field"},"visibility":"public"}],"return_type":null,"error_types":{"8459317586968962522":{"error_kind":"string","string":"Leaf index mismatch"},"12469291177396340830":{"error_kind":"string","string":"call to assert_max_bit_size"},"12603685718704375722":{"error_kind":"string","string":"Invalid nullifier"},"14489152648901838370":{"error_kind":"string","string":"ECDH resulted in point at infinity"},"15764276373176857197":{"error_kind":"string","string":"Stack too deep"},"16915715315846645806":{"error_kind":"string","string":"Commitment not in Merkle tree"}}},"bytecode":"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","debug_symbols":"tdndbuI6EAfwd8l1Lzz2fNh9ldWqoi27QkK0YtuVjqq++3Ho/AOsZIsTn73puIB/2MlM7ISP6Xn7+P7zYXf48fJruv/2MT0ed/v97ufD/uVp87Z7OdRXP6Yw/yGd7uPdRPYV8nSfaijTPd9NsX6CP+u/+KB8vWWf9UVQD2/H7Xb+wIVdv/F1c9we3qb7w/t+fzf93uzfTx/69bo5nOLb5ljfDXfT9vBcYwV/7PbbufV5d+4d2l1zZO+cOS/dya76U7u/qnp/NVnR30Ly/kZhVf+I/rH5/Z35FxLvXyKt6S8Z/a20+mu7P1FgzKC29WIO+dYxRAuYRDS2RRC6EnJbSNlwGlO5OA96nUelI1AwCMQXs9DrM9mZBhVBLlCxdjL0jkSIOJgxcDsfY5sQwyD0MiHzfxiD5mUMpZlTxH9zDJQLxlDHs+pQUk7jRBglEhGIJO2c6GQmpYLqIKa0iuDEC8H/A2HrCKGFUF1JhIXINDyRlYSEZSJCYZhIKwk+E8otIubROu2OYSky0naFpDA4hl6FFcPlKoXIrcUjxe6FeynSEFJr9egSTLpklUiT6Fw0WQoSk5W1tQLdTpQm0ZuILCtQTTBrTST0VlKWZSUtqXlC8vgJ6a3ngmnUM3Mew3VacS+v4nkJqonVJKi3N9Lz1ijLqlHYklfRLq4TfxKpMwpbKoystCfSyauynNG6XVwD0Hlfc7VH/JPobDTrtRqD4CznaVC5/UiUUJYNWmweiV5u190lcpvbO1XuJGY8F1gUbea2hMHcFhrObYnDud0dxW25LTyc2yKDud0DbsxtseHc7h6J8dyW5VY6aWrmtobePArOKBeiVURJtBBS1hB1a4WkkMCrRiG0jEKIVx0LSYJjISm3JyKDda46XOdqw3XeHcVtda5luM4tDNZ5D7ixzi0O13n3SIzXuS73UEkttxKzV6OU0pKYJbQE094mMS67dsq5tQqaDVaH5eHqsDJcHd1R3FYdmYarI8fB6ugBN1ZH5uHq6B6J4ergyHgOyPV8XOX29/rf5ml3vH5+Pj8enx/yRJpvW2uM811LjckjzzepNYpHnXO+RvM4P2yvE4/1kXqq353mx+1zJI/RY5rnUSN7FI/Vm7MwmcfssXxFDh7JY/SYPLJH8egeu8fusXvinrgn7ol74p64J+6Je+KeuKfuqXvqnrqn7ql76p66p+6pe+aeuWfumXvmnrln7pl75p65l93L7mX3snvZvexedi+7l93L7hX3invFveJeca+4V9wr7hX3insUAhqERkQjocFoCBqKhqGR0YBMkAkyQSbIBJkgE2SCTJAJcoQcIUfIEfJcODr/DDVXjp0aioahkdEo3pjL56tBaEQ0EhqMBuQEOUFOkBNkhsyQGTJDZsgMmSEzZIbMkAWyQBbIAlkgC2SBLJAFskBWyApZIStkhayQFbJCVsgK2SAbZINskA2yQTbIBtkgG+QMOUPOkDPkDDlDzpAz5Ax5rjw7/WhZ5XxqEBpVzvP+/vfmuNs87rfzJX2+6L8fnnCFr/++/fOKd/Ab6uvx5Wn7/H7czqvBxQ+p9e+3eiMVy/flJ9PTS3aX4vfPeRH5Fw==","file_map":{"16":{"source":"use crate::cmp::Eq;\nuse crate::hash::Hash;\nuse crate::ops::arith::{Add, Neg, Sub};\n\n/// A point on the embedded elliptic curve\n/// By definition, the base field of the embedded curve is the scalar field of the proof system curve, i.e the Noir Field.\n/// x and y denotes the Weierstrass coordinates of the point, if is_infinite is false.\npub struct EmbeddedCurvePoint {\n    pub x: Field,\n    pub y: Field,\n    pub is_infinite: bool,\n}\n\nimpl EmbeddedCurvePoint {\n    /// Elliptic curve point doubling operation\n    /// returns the doubled point of a point P, i.e P+P\n    pub fn double(self) -> EmbeddedCurvePoint {\n        embedded_curve_add(self, self)\n    }\n\n    /// Returns the null element of the curve; 'the point at infinity'\n    pub fn point_at_infinity() -> EmbeddedCurvePoint {\n        EmbeddedCurvePoint { x: 0, y: 0, is_infinite: true }\n    }\n\n    /// Returns the curve's generator point.\n    pub fn generator() -> EmbeddedCurvePoint {\n        // Generator point for the grumpkin curve (y^2 = x^3 - 17)\n        EmbeddedCurvePoint {\n            x: 1,\n            y: 17631683881184975370165255887551781615748388533673675138860, // sqrt(-16)\n            is_infinite: false,\n        }\n    }\n}\n\nimpl Add for EmbeddedCurvePoint {\n    /// Adds two points P+Q, using the curve addition formula, and also handles point at infinity\n    fn add(self, other: EmbeddedCurvePoint) -> EmbeddedCurvePoint {\n        embedded_curve_add(self, other)\n    }\n}\n\nimpl Sub for EmbeddedCurvePoint {\n    /// Points subtraction operation, using addition and negation\n    fn sub(self, other: EmbeddedCurvePoint) -> EmbeddedCurvePoint {\n        self + other.neg()\n    }\n}\n\nimpl Neg for EmbeddedCurvePoint {\n    /// Negates a point P, i.e returns -P, by negating the y coordinate.\n    /// If the point is at infinity, then the result is also at infinity.\n    fn neg(self) -> EmbeddedCurvePoint {\n        EmbeddedCurvePoint { x: self.x, y: -self.y, is_infinite: self.is_infinite }\n    }\n}\n\nimpl Eq for EmbeddedCurvePoint {\n    /// Checks whether two points are equal\n    fn eq(self: Self, b: EmbeddedCurvePoint) -> bool {\n        (self.is_infinite & b.is_infinite)\n            | ((self.is_infinite == b.is_infinite) & (self.x == b.x) & (self.y == b.y))\n    }\n}\n\nimpl Hash for EmbeddedCurvePoint {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: crate::hash::Hasher,\n    {\n        if self.is_infinite {\n            self.is_infinite.hash(state);\n        } else {\n            self.x.hash(state);\n            self.y.hash(state);\n        }\n    }\n}\n\n/// Scalar for the embedded curve represented as low and high limbs\n/// By definition, the scalar field of the embedded curve is base field of the proving system curve.\n/// It may not fit into a Field element, so it is represented with two Field elements; its low and high limbs.\npub struct EmbeddedCurveScalar {\n    pub lo: Field,\n    pub hi: Field,\n}\n\nimpl EmbeddedCurveScalar {\n    pub fn new(lo: Field, hi: Field) -> Self {\n        EmbeddedCurveScalar { lo, hi }\n    }\n\n    #[field(bn254)]\n    pub fn from_field(scalar: Field) -> EmbeddedCurveScalar {\n        let (a, b) = crate::field::bn254::decompose(scalar);\n        EmbeddedCurveScalar { lo: a, hi: b }\n    }\n\n    //Bytes to scalar: take the first (after the specified offset) 16 bytes of the input as the lo value, and the next 16 bytes as the hi value\n    #[field(bn254)]\n    pub(crate) fn from_bytes(bytes: [u8; 64], offset: u32) -> EmbeddedCurveScalar {\n        let mut v = 1;\n        let mut lo = 0 as Field;\n        let mut hi = 0 as Field;\n        for i in 0..16 {\n            lo = lo + (bytes[offset + 31 - i] as Field) * v;\n            hi = hi + (bytes[offset + 15 - i] as Field) * v;\n            v = v * 256;\n        }\n        let sig_s = crate::embedded_curve_ops::EmbeddedCurveScalar { lo, hi };\n        sig_s\n    }\n}\n\nimpl Eq for EmbeddedCurveScalar {\n    fn eq(self, other: Self) -> bool {\n        (other.hi == self.hi) & (other.lo == self.lo)\n    }\n}\n\nimpl Hash for EmbeddedCurveScalar {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: crate::hash::Hasher,\n    {\n        self.hi.hash(state);\n        self.lo.hash(state);\n    }\n}\n\n// Computes a multi scalar multiplication over the embedded curve.\n// For bn254, We have Grumpkin and Baby JubJub.\n// For bls12-381, we have JubJub and Bandersnatch.\n//\n// The embedded curve being used is decided by the\n// underlying proof system.\n// docs:start:multi_scalar_mul\npub fn multi_scalar_mul<let N: u32>(\n    points: [EmbeddedCurvePoint; N],\n    scalars: [EmbeddedCurveScalar; N],\n) -> EmbeddedCurvePoint\n// docs:end:multi_scalar_mul\n{\n    multi_scalar_mul_array_return(points, scalars, true)[0]\n}\n\n#[foreign(multi_scalar_mul)]\npub(crate) fn multi_scalar_mul_array_return<let N: u32>(\n    points: [EmbeddedCurvePoint; N],\n    scalars: [EmbeddedCurveScalar; N],\n    predicate: bool,\n) -> [EmbeddedCurvePoint; 1] {}\n\n// docs:start:fixed_base_scalar_mul\npub fn fixed_base_scalar_mul(scalar: EmbeddedCurveScalar) -> EmbeddedCurvePoint\n// docs:end:fixed_base_scalar_mul\n{\n    multi_scalar_mul([EmbeddedCurvePoint::generator()], [scalar])\n}\n\n/// This function assumes that the points are on the curve\n// docs:start:embedded_curve_add\npub fn embedded_curve_add(\n    point1: EmbeddedCurvePoint,\n    point2: EmbeddedCurvePoint,\n) -> EmbeddedCurvePoint {\n    // docs:end:embedded_curve_add\n    if crate::runtime::is_unconstrained() {\n        // avoid calling the black box function for trivial cases\n        if point1.is_infinite {\n            point2\n        } else if point2.is_infinite {\n            point1\n        } else {\n            embedded_curve_add_inner(point1, point2)\n        }\n    } else {\n        embedded_curve_add_inner(point1, point2)\n    }\n}\n\n#[foreign(embedded_curve_add)]\nfn embedded_curve_add_array_return(\n    _point1: EmbeddedCurvePoint,\n    _point2: EmbeddedCurvePoint,\n    _predicate: bool,\n) -> [EmbeddedCurvePoint; 1] {}\n\n/// EC addition wrapper for the foreign function\nfn embedded_curve_add_inner(\n    point1: EmbeddedCurvePoint,\n    point2: EmbeddedCurvePoint,\n) -> EmbeddedCurvePoint {\n    embedded_curve_add_array_return(point1, point2, true)[0]\n}\n","path":"std/embedded_curve_ops.nr"},"17":{"source":"use crate::field::field_less_than;\nuse crate::runtime::is_unconstrained;\n\n// The low and high decomposition of the field modulus\npub(crate) global PLO: Field = 53438638232309528389504892708671455233;\npub(crate) global PHI: Field = 64323764613183177041862057485226039389;\n\npub(crate) global TWO_POW_128: Field = 0x100000000000000000000000000000000;\n\n// Decomposes a single field into two 16 byte fields.\nfn compute_decomposition(x: Field) -> (Field, Field) {\n    // Here's we're taking advantage of truncating 128 bit limbs from the input field\n    // and then subtracting them from the input such the field division is equivalent to integer division.\n    let low = (x as u128) as Field;\n    let high = (x - low) / TWO_POW_128;\n\n    (low, high)\n}\n\npub(crate) unconstrained fn decompose_hint(x: Field) -> (Field, Field) {\n    compute_decomposition(x)\n}\n\nunconstrained fn lte_hint(x: Field, y: Field) -> bool {\n    if x == y {\n        true\n    } else {\n        field_less_than(x, y)\n    }\n}\n\n// Assert that (alo > blo && ahi >= bhi) || (alo <= blo && ahi > bhi)\nfn assert_gt_limbs(a: (Field, Field), b: (Field, Field)) {\n    let (alo, ahi) = a;\n    let (blo, bhi) = b;\n    // Safety: borrow is enforced to be boolean due to its type.\n    // if borrow is 0, it asserts that (alo > blo && ahi >= bhi)\n    // if borrow is 1, it asserts that (alo <= blo && ahi > bhi)\n    unsafe {\n        let borrow = lte_hint(alo, blo);\n\n        let rlo = alo - blo - 1 + (borrow as Field) * TWO_POW_128;\n        let rhi = ahi - bhi - (borrow as Field);\n\n        rlo.assert_max_bit_size::<128>();\n        rhi.assert_max_bit_size::<128>();\n    }\n}\n\n/// Decompose a single field into two 16 byte fields.\npub fn decompose(x: Field) -> (Field, Field) {\n    if is_unconstrained() {\n        compute_decomposition(x)\n    } else {\n        // Safety: decomposition is properly checked below\n        unsafe {\n            // Take hints of the decomposition\n            let (xlo, xhi) = decompose_hint(x);\n\n            // Range check the limbs\n            xlo.assert_max_bit_size::<128>();\n            xhi.assert_max_bit_size::<128>();\n\n            // Check that the decomposition is correct\n            assert_eq(x, xlo + TWO_POW_128 * xhi);\n\n            // Assert that the decomposition of P is greater than the decomposition of x\n            assert_gt_limbs((PLO, PHI), (xlo, xhi));\n            (xlo, xhi)\n        }\n    }\n}\n\npub fn assert_gt(a: Field, b: Field) {\n    if is_unconstrained() {\n        assert(\n            // Safety: already unconstrained\n            unsafe { field_less_than(b, a) },\n        );\n    } else {\n        // Decompose a and b\n        let a_limbs = decompose(a);\n        let b_limbs = decompose(b);\n\n        // Assert that a_limbs is greater than b_limbs\n        assert_gt_limbs(a_limbs, b_limbs)\n    }\n}\n\npub fn assert_lt(a: Field, b: Field) {\n    assert_gt(b, a);\n}\n\npub fn gt(a: Field, b: Field) -> bool {\n    if is_unconstrained() {\n        // Safety: unsafe in unconstrained\n        unsafe {\n            field_less_than(b, a)\n        }\n    } else if a == b {\n        false\n    } else {\n        // Safety: Take a hint of the comparison and verify it\n        unsafe {\n            if field_less_than(a, b) {\n                assert_gt(b, a);\n                false\n            } else {\n                assert_gt(a, b);\n                true\n            }\n        }\n    }\n}\n\npub fn lt(a: Field, b: Field) -> bool {\n    gt(b, a)\n}\n\nmod tests {\n    // TODO: Allow imports from \"super\"\n    use crate::field::bn254::{assert_gt, decompose, gt, lt, lte_hint, PHI, PLO, TWO_POW_128};\n\n    #[test]\n    fn check_decompose() {\n        assert_eq(decompose(TWO_POW_128), (0, 1));\n        assert_eq(decompose(TWO_POW_128 + 0x1234567890), (0x1234567890, 1));\n        assert_eq(decompose(0x1234567890), (0x1234567890, 0));\n    }\n\n    #[test]\n    unconstrained fn check_lte_hint() {\n        assert(lte_hint(0, 1));\n        assert(lte_hint(0, 0x100));\n        assert(lte_hint(0x100, TWO_POW_128 - 1));\n        assert(!lte_hint(0 - 1, 0));\n\n        assert(lte_hint(0, 0));\n        assert(lte_hint(0x100, 0x100));\n        assert(lte_hint(0 - 1, 0 - 1));\n    }\n\n    #[test]\n    fn check_gt() {\n        assert(gt(1, 0));\n        assert(gt(0x100, 0));\n        assert(gt((0 - 1), (0 - 2)));\n        assert(gt(TWO_POW_128, 0));\n        assert(!gt(0, 0));\n        assert(!gt(0, 0x100));\n        assert(gt(0 - 1, 0 - 2));\n        assert(!gt(0 - 2, 0 - 1));\n        assert_gt(0 - 1, 0);\n    }\n\n    #[test]\n    fn check_plo_phi() {\n        assert_eq(PLO + PHI * TWO_POW_128, 0);\n        let p_bytes = crate::field::modulus_le_bytes();\n        let mut p_low: Field = 0;\n        let mut p_high: Field = 0;\n\n        let mut offset = 1;\n        for i in 0..16 {\n            p_low += (p_bytes[i] as Field) * offset;\n            p_high += (p_bytes[i + 16] as Field) * offset;\n            offset *= 256;\n        }\n        assert_eq(p_low, PLO);\n        assert_eq(p_high, PHI);\n    }\n\n    #[test]\n    fn check_decompose_edge_cases() {\n        assert_eq(decompose(0), (0, 0));\n        assert_eq(decompose(TWO_POW_128 - 1), (TWO_POW_128 - 1, 0));\n        assert_eq(decompose(TWO_POW_128 + 1), (1, 1));\n        assert_eq(decompose(TWO_POW_128 * 2), (0, 2));\n        assert_eq(decompose(TWO_POW_128 * 2 + 0x1234567890), (0x1234567890, 2));\n    }\n\n    #[test]\n    fn check_decompose_large_values() {\n        let large_field = 0xffffffffffffffff;\n        let (lo, hi) = decompose(large_field);\n        assert_eq(large_field, lo + TWO_POW_128 * hi);\n\n        let large_value = large_field - TWO_POW_128;\n        let (lo2, hi2) = decompose(large_value);\n        assert_eq(large_value, lo2 + TWO_POW_128 * hi2);\n    }\n\n    #[test]\n    fn check_lt_comprehensive() {\n        assert(lt(0, 1));\n        assert(!lt(1, 0));\n        assert(!lt(0, 0));\n        assert(!lt(42, 42));\n\n        assert(lt(TWO_POW_128 - 1, TWO_POW_128));\n        assert(!lt(TWO_POW_128, TWO_POW_128 - 1));\n    }\n}\n","path":"std/field/bn254.nr"},"18":{"source":"pub mod bn254;\nuse crate::{runtime::is_unconstrained, static_assert};\nuse bn254::lt as bn254_lt;\n\nimpl Field {\n    /// Asserts that `self` can be represented in `bit_size` bits.\n    ///\n    /// # Failures\n    /// Causes a constraint failure for `Field` values exceeding `2^{bit_size}`.\n    // docs:start:assert_max_bit_size\n    pub fn assert_max_bit_size<let BIT_SIZE: u32>(self) {\n        // docs:end:assert_max_bit_size\n        static_assert(\n            BIT_SIZE < modulus_num_bits() as u32,\n            \"BIT_SIZE must be less than modulus_num_bits\",\n        );\n        __assert_max_bit_size(self, BIT_SIZE);\n    }\n\n    /// Decomposes `self` into its little endian bit decomposition as a `[u1; N]` array.\n    /// This array will be zero padded should not all bits be necessary to represent `self`.\n    ///\n    /// # Failures\n    /// Causes a constraint failure for `Field` values exceeding `2^N` as the resulting array will not\n    /// be able to represent the original `Field`.\n    ///\n    /// # Safety\n    /// The bit decomposition returned is canonical and is guaranteed to not overflow the modulus.\n    // docs:start:to_le_bits\n    pub fn to_le_bits<let N: u32>(self: Self) -> [u1; N] {\n        // docs:end:to_le_bits\n        let bits = __to_le_bits(self);\n\n        if !is_unconstrained() {\n            // Ensure that the byte decomposition does not overflow the modulus\n            let p = modulus_le_bits();\n            assert(bits.len() <= p.len());\n            let mut ok = bits.len() != p.len();\n            for i in 0..N {\n                if !ok {\n                    if (bits[N - 1 - i] != p[N - 1 - i]) {\n                        assert(p[N - 1 - i] == 1);\n                        ok = true;\n                    }\n                }\n            }\n            assert(ok);\n        }\n        bits\n    }\n\n    /// Decomposes `self` into its big endian bit decomposition as a `[u1; N]` array.\n    /// This array will be zero padded should not all bits be necessary to represent `self`.\n    ///\n    /// # Failures\n    /// Causes a constraint failure for `Field` values exceeding `2^N` as the resulting array will not\n    /// be able to represent the original `Field`.\n    ///\n    /// # Safety\n    /// The bit decomposition returned is canonical and is guaranteed to not overflow the modulus.\n    // docs:start:to_be_bits\n    pub fn to_be_bits<let N: u32>(self: Self) -> [u1; N] {\n        // docs:end:to_be_bits\n        let bits = __to_be_bits(self);\n\n        if !is_unconstrained() {\n            // Ensure that the decomposition does not overflow the modulus\n            let p = modulus_be_bits();\n            assert(bits.len() <= p.len());\n            let mut ok = bits.len() != p.len();\n            for i in 0..N {\n                if !ok {\n                    if (bits[i] != p[i]) {\n                        assert(p[i] == 1);\n                        ok = true;\n                    }\n                }\n            }\n            assert(ok);\n        }\n        bits\n    }\n\n    /// Decomposes `self` into its little endian byte decomposition as a `[u8;N]` array\n    /// This array will be zero padded should not all bytes be necessary to represent `self`.\n    ///\n    /// # Failures\n    ///  The length N of the array must be big enough to contain all the bytes of the 'self',\n    ///  and no more than the number of bytes required to represent the field modulus\n    ///\n    /// # Safety\n    /// The result is ensured to be the canonical decomposition of the field element\n    // docs:start:to_le_bytes\n    pub fn to_le_bytes<let N: u32>(self: Self) -> [u8; N] {\n        // docs:end:to_le_bytes\n        static_assert(\n            N <= modulus_le_bytes().len(),\n            \"N must be less than or equal to modulus_le_bytes().len()\",\n        );\n        // Compute the byte decomposition\n        let bytes = self.to_le_radix(256);\n\n        if !is_unconstrained() {\n            // Ensure that the byte decomposition does not overflow the modulus\n            let p = modulus_le_bytes();\n            assert(bytes.len() <= p.len());\n            let mut ok = bytes.len() != p.len();\n            for i in 0..N {\n                if !ok {\n                    if (bytes[N - 1 - i] != p[N - 1 - i]) {\n                        assert(bytes[N - 1 - i] < p[N - 1 - i]);\n                        ok = true;\n                    }\n                }\n            }\n            assert(ok);\n        }\n        bytes\n    }\n\n    /// Decomposes `self` into its big endian byte decomposition as a `[u8;N]` array of length required to represent the field modulus\n    /// This array will be zero padded should not all bytes be necessary to represent `self`.\n    ///\n    /// # Failures\n    ///  The length N of the array must be big enough to contain all the bytes of the 'self',\n    ///  and no more than the number of bytes required to represent the field modulus\n    ///\n    /// # Safety\n    /// The result is ensured to be the canonical decomposition of the field element\n    // docs:start:to_be_bytes\n    pub fn to_be_bytes<let N: u32>(self: Self) -> [u8; N] {\n        // docs:end:to_be_bytes\n        static_assert(\n            N <= modulus_le_bytes().len(),\n            \"N must be less than or equal to modulus_le_bytes().len()\",\n        );\n        // Compute the byte decomposition\n        let bytes = self.to_be_radix(256);\n\n        if !is_unconstrained() {\n            // Ensure that the byte decomposition does not overflow the modulus\n            let p = modulus_be_bytes();\n            assert(bytes.len() <= p.len());\n            let mut ok = bytes.len() != p.len();\n            for i in 0..N {\n                if !ok {\n                    if (bytes[i] != p[i]) {\n                        assert(bytes[i] < p[i]);\n                        ok = true;\n                    }\n                }\n            }\n            assert(ok);\n        }\n        bytes\n    }\n\n    fn to_le_radix<let N: u32>(self: Self, radix: u32) -> [u8; N] {\n        // Brillig does not need an immediate radix\n        if !crate::runtime::is_unconstrained() {\n            static_assert(1 < radix, \"radix must be greater than 1\");\n            static_assert(radix <= 256, \"radix must be less than or equal to 256\");\n            static_assert(radix & (radix - 1) == 0, \"radix must be a power of 2\");\n        }\n        __to_le_radix(self, radix)\n    }\n\n    fn to_be_radix<let N: u32>(self: Self, radix: u32) -> [u8; N] {\n        // Brillig does not need an immediate radix\n        if !crate::runtime::is_unconstrained() {\n            static_assert(1 < radix, \"radix must be greater than 1\");\n            static_assert(radix <= 256, \"radix must be less than or equal to 256\");\n            static_assert(radix & (radix - 1) == 0, \"radix must be a power of 2\");\n        }\n        __to_be_radix(self, radix)\n    }\n\n    // Returns self to the power of the given exponent value.\n    // Caution: we assume the exponent fits into 32 bits\n    // using a bigger bit size impacts negatively the performance and should be done only if the exponent does not fit in 32 bits\n    pub fn pow_32(self, exponent: Field) -> Field {\n        let mut r: Field = 1;\n        let b: [u1; 32] = exponent.to_le_bits();\n\n        for i in 1..33 {\n            r *= r;\n            r = (b[32 - i] as Field) * (r * self) + (1 - b[32 - i] as Field) * r;\n        }\n        r\n    }\n\n    // Parity of (prime) Field element, i.e. sgn0(x mod p) = 0 if x `elem` {0, ..., p-1} is even, otherwise sgn0(x mod p) = 1.\n    pub fn sgn0(self) -> u1 {\n        self as u1\n    }\n\n    pub fn lt(self, another: Field) -> bool {\n        if crate::compat::is_bn254() {\n            bn254_lt(self, another)\n        } else {\n            lt_fallback(self, another)\n        }\n    }\n\n    /// Convert a little endian byte array to a field element.\n    /// If the provided byte array overflows the field modulus then the Field will silently wrap around.\n    pub fn from_le_bytes<let N: u32>(bytes: [u8; N]) -> Field {\n        static_assert(\n            N <= modulus_le_bytes().len(),\n            \"N must be less than or equal to modulus_le_bytes().len()\",\n        );\n        let mut v = 1;\n        let mut result = 0;\n\n        for i in 0..N {\n            result += (bytes[i] as Field) * v;\n            v = v * 256;\n        }\n        result\n    }\n\n    /// Convert a big endian byte array to a field element.\n    /// If the provided byte array overflows the field modulus then the Field will silently wrap around.\n    pub fn from_be_bytes<let N: u32>(bytes: [u8; N]) -> Field {\n        let mut v = 1;\n        let mut result = 0;\n\n        for i in 0..N {\n            result += (bytes[N - 1 - i] as Field) * v;\n            v = v * 256;\n        }\n        result\n    }\n}\n\n#[builtin(apply_range_constraint)]\nfn __assert_max_bit_size(value: Field, bit_size: u32) {}\n\n// `_radix` must be less than 256\n#[builtin(to_le_radix)]\nfn __to_le_radix<let N: u32>(value: Field, radix: u32) -> [u8; N] {}\n\n// `_radix` must be less than 256\n#[builtin(to_be_radix)]\nfn __to_be_radix<let N: u32>(value: Field, radix: u32) -> [u8; N] {}\n\n/// Decomposes `self` into its little endian bit decomposition as a `[u1; N]` array.\n/// This array will be zero padded should not all bits be necessary to represent `self`.\n///\n/// # Failures\n/// Causes a constraint failure for `Field` values exceeding `2^N` as the resulting array will not\n/// be able to represent the original `Field`.\n///\n/// # Safety\n/// Values of `N` equal to or greater than the number of bits necessary to represent the `Field` modulus\n/// (e.g. 254 for the BN254 field) allow for multiple bit decompositions. This is due to how the `Field` will\n/// wrap around due to overflow when verifying the decomposition.\n#[builtin(to_le_bits)]\nfn __to_le_bits<let N: u32>(value: Field) -> [u1; N] {}\n\n/// Decomposes `self` into its big endian bit decomposition as a `[u1; N]` array.\n/// This array will be zero padded should not all bits be necessary to represent `self`.\n///\n/// # Failures\n/// Causes a constraint failure for `Field` values exceeding `2^N` as the resulting array will not\n/// be able to represent the original `Field`.\n///\n/// # Safety\n/// Values of `N` equal to or greater than the number of bits necessary to represent the `Field` modulus\n/// (e.g. 254 for the BN254 field) allow for multiple bit decompositions. This is due to how the `Field` will\n/// wrap around due to overflow when verifying the decomposition.\n#[builtin(to_be_bits)]\nfn __to_be_bits<let N: u32>(value: Field) -> [u1; N] {}\n\n#[builtin(modulus_num_bits)]\npub comptime fn modulus_num_bits() -> u64 {}\n\n#[builtin(modulus_be_bits)]\npub comptime fn modulus_be_bits() -> [u1] {}\n\n#[builtin(modulus_le_bits)]\npub comptime fn modulus_le_bits() -> [u1] {}\n\n#[builtin(modulus_be_bytes)]\npub comptime fn modulus_be_bytes() -> [u8] {}\n\n#[builtin(modulus_le_bytes)]\npub comptime fn modulus_le_bytes() -> [u8] {}\n\n/// An unconstrained only built in to efficiently compare fields.\n#[builtin(field_less_than)]\nunconstrained fn __field_less_than(x: Field, y: Field) -> bool {}\n\npub(crate) unconstrained fn field_less_than(x: Field, y: Field) -> bool {\n    __field_less_than(x, y)\n}\n\n// Convert a 32 byte array to a field element by modding\npub fn bytes32_to_field(bytes32: [u8; 32]) -> Field {\n    // Convert it to a field element\n    let mut v = 1;\n    let mut high = 0 as Field;\n    let mut low = 0 as Field;\n\n    for i in 0..16 {\n        high = high + (bytes32[15 - i] as Field) * v;\n        low = low + (bytes32[16 + 15 - i] as Field) * v;\n        v = v * 256;\n    }\n    // Abuse that a % p + b % p = (a + b) % p and that low < p\n    low + high * v\n}\n\nfn lt_fallback(x: Field, y: Field) -> bool {\n    if is_unconstrained() {\n        // Safety: unconstrained context\n        unsafe {\n            field_less_than(x, y)\n        }\n    } else {\n        let x_bytes: [u8; 32] = x.to_le_bytes();\n        let y_bytes: [u8; 32] = y.to_le_bytes();\n        let mut x_is_lt = false;\n        let mut done = false;\n        for i in 0..32 {\n            if (!done) {\n                let x_byte = x_bytes[32 - 1 - i] as u8;\n                let y_byte = y_bytes[32 - 1 - i] as u8;\n                let bytes_match = x_byte == y_byte;\n                if !bytes_match {\n                    x_is_lt = x_byte < y_byte;\n                    done = true;\n                }\n            }\n        }\n        x_is_lt\n    }\n}\n\nmod tests {\n    use crate::{panic::panic, runtime, static_assert};\n    use super::{\n        field_less_than, modulus_be_bits, modulus_be_bytes, modulus_le_bits, modulus_le_bytes,\n    };\n\n    #[test]\n    // docs:start:to_be_bits_example\n    fn test_to_be_bits() {\n        let field = 2;\n        let bits: [u1; 8] = field.to_be_bits();\n        assert_eq(bits, [0, 0, 0, 0, 0, 0, 1, 0]);\n    }\n    // docs:end:to_be_bits_example\n\n    #[test]\n    // docs:start:to_le_bits_example\n    fn test_to_le_bits() {\n        let field = 2;\n        let bits: [u1; 8] = field.to_le_bits();\n        assert_eq(bits, [0, 1, 0, 0, 0, 0, 0, 0]);\n    }\n    // docs:end:to_le_bits_example\n\n    #[test]\n    // docs:start:to_be_bytes_example\n    fn test_to_be_bytes() {\n        let field = 2;\n        let bytes: [u8; 8] = field.to_be_bytes();\n        assert_eq(bytes, [0, 0, 0, 0, 0, 0, 0, 2]);\n        assert_eq(Field::from_be_bytes::<8>(bytes), field);\n    }\n    // docs:end:to_be_bytes_example\n\n    #[test]\n    // docs:start:to_le_bytes_example\n    fn test_to_le_bytes() {\n        let field = 2;\n        let bytes: [u8; 8] = field.to_le_bytes();\n        assert_eq(bytes, [2, 0, 0, 0, 0, 0, 0, 0]);\n        assert_eq(Field::from_le_bytes::<8>(bytes), field);\n    }\n    // docs:end:to_le_bytes_example\n\n    #[test]\n    // docs:start:to_be_radix_example\n    fn test_to_be_radix() {\n        // 259, in base 256, big endian, is [1, 3].\n        // i.e. 3 * 256^0 + 1 * 256^1\n        let field = 259;\n\n        // The radix (in this example, 256) must be a power of 2.\n        // The length of the returned byte array can be specified to be\n        // >= the amount of space needed.\n        let bytes: [u8; 8] = field.to_be_radix(256);\n        assert_eq(bytes, [0, 0, 0, 0, 0, 0, 1, 3]);\n        assert_eq(Field::from_be_bytes::<8>(bytes), field);\n    }\n    // docs:end:to_be_radix_example\n\n    #[test]\n    // docs:start:to_le_radix_example\n    fn test_to_le_radix() {\n        // 259, in base 256, little endian, is [3, 1].\n        // i.e. 3 * 256^0 + 1 * 256^1\n        let field = 259;\n\n        // The radix (in this example, 256) must be a power of 2.\n        // The length of the returned byte array can be specified to be\n        // >= the amount of space needed.\n        let bytes: [u8; 8] = field.to_le_radix(256);\n        assert_eq(bytes, [3, 1, 0, 0, 0, 0, 0, 0]);\n        assert_eq(Field::from_le_bytes::<8>(bytes), field);\n    }\n    // docs:end:to_le_radix_example\n\n    #[test(should_fail_with = \"radix must be greater than 1\")]\n    fn test_to_le_radix_1() {\n        // this test should only fail in constrained mode\n        if !runtime::is_unconstrained() {\n            let field = 2;\n            let _: [u8; 8] = field.to_le_radix(1);\n        } else {\n            panic(\"radix must be greater than 1\");\n        }\n    }\n\n    // Updated test to account for Brillig restriction that radix must be greater than 2\n    #[test(should_fail_with = \"radix must be greater than 1\")]\n    fn test_to_le_radix_brillig_1() {\n        // this test should only fail in constrained mode\n        if !runtime::is_unconstrained() {\n            let field = 1;\n            let _: [u8; 8] = field.to_le_radix(1);\n        } else {\n            panic(\"radix must be greater than 1\");\n        }\n    }\n\n    #[test(should_fail_with = \"radix must be a power of 2\")]\n    fn test_to_le_radix_3() {\n        // this test should only fail in constrained mode\n        if !runtime::is_unconstrained() {\n            let field = 2;\n            let _: [u8; 8] = field.to_le_radix(3);\n        } else {\n            panic(\"radix must be a power of 2\");\n        }\n    }\n\n    #[test]\n    fn test_to_le_radix_brillig_3() {\n        // this test should only fail in constrained mode\n        if runtime::is_unconstrained() {\n            let field = 1;\n            let out: [u8; 8] = field.to_le_radix(3);\n            let mut expected = [0; 8];\n            expected[0] = 1;\n            assert(out == expected, \"unexpected result\");\n        }\n    }\n\n    #[test(should_fail_with = \"radix must be less than or equal to 256\")]\n    fn test_to_le_radix_512() {\n        // this test should only fail in constrained mode\n        if !runtime::is_unconstrained() {\n            let field = 2;\n            let _: [u8; 8] = field.to_le_radix(512);\n        } else {\n            panic(\"radix must be less than or equal to 256\")\n        }\n    }\n\n    #[test(should_fail_with = \"Field failed to decompose into specified 16 limbs\")]\n    unconstrained fn not_enough_limbs_brillig() {\n        let _: [u8; 16] = 0x100000000000000000000000000000000.to_le_bytes();\n    }\n\n    #[test(should_fail_with = \"Field failed to decompose into specified 16 limbs\")]\n    fn not_enough_limbs() {\n        let _: [u8; 16] = 0x100000000000000000000000000000000.to_le_bytes();\n    }\n\n    #[test]\n    unconstrained fn test_field_less_than() {\n        assert(field_less_than(0, 1));\n        assert(field_less_than(0, 0x100));\n        assert(field_less_than(0x100, 0 - 1));\n        assert(!field_less_than(0 - 1, 0));\n    }\n\n    #[test]\n    unconstrained fn test_large_field_values_unconstrained() {\n        let large_field = 0xffffffffffffffff;\n\n        let bits: [u1; 64] = large_field.to_le_bits();\n        assert_eq(bits[0], 1);\n\n        let bytes: [u8; 8] = large_field.to_le_bytes();\n        assert_eq(Field::from_le_bytes::<8>(bytes), large_field);\n\n        let radix_bytes: [u8; 8] = large_field.to_le_radix(256);\n        assert_eq(Field::from_le_bytes::<8>(radix_bytes), large_field);\n    }\n\n    #[test]\n    fn test_large_field_values() {\n        let large_val = 0xffffffffffffffff;\n\n        let bits: [u1; 64] = large_val.to_le_bits();\n        assert_eq(bits[0], 1);\n\n        let bytes: [u8; 8] = large_val.to_le_bytes();\n        assert_eq(Field::from_le_bytes::<8>(bytes), large_val);\n\n        let radix_bytes: [u8; 8] = large_val.to_le_radix(256);\n        assert_eq(Field::from_le_bytes::<8>(radix_bytes), large_val);\n    }\n\n    #[test]\n    fn test_decomposition_edge_cases() {\n        let zero_bits: [u1; 8] = 0.to_le_bits();\n        assert_eq(zero_bits, [0; 8]);\n\n        let zero_bytes: [u8; 8] = 0.to_le_bytes();\n        assert_eq(zero_bytes, [0; 8]);\n\n        let one_bits: [u1; 8] = 1.to_le_bits();\n        let expected: [u1; 8] = [1, 0, 0, 0, 0, 0, 0, 0];\n        assert_eq(one_bits, expected);\n\n        let pow2_bits: [u1; 8] = 4.to_le_bits();\n        let expected: [u1; 8] = [0, 0, 1, 0, 0, 0, 0, 0];\n        assert_eq(pow2_bits, expected);\n    }\n\n    #[test]\n    fn test_pow_32() {\n        assert_eq(2.pow_32(3), 8);\n        assert_eq(3.pow_32(2), 9);\n        assert_eq(5.pow_32(0), 1);\n        assert_eq(7.pow_32(1), 7);\n\n        assert_eq(2.pow_32(10), 1024);\n\n        assert_eq(0.pow_32(5), 0);\n        assert_eq(0.pow_32(0), 1);\n\n        assert_eq(1.pow_32(100), 1);\n    }\n\n    #[test]\n    fn test_sgn0() {\n        assert_eq(0.sgn0(), 0);\n        assert_eq(2.sgn0(), 0);\n        assert_eq(4.sgn0(), 0);\n        assert_eq(100.sgn0(), 0);\n\n        assert_eq(1.sgn0(), 1);\n        assert_eq(3.sgn0(), 1);\n        assert_eq(5.sgn0(), 1);\n        assert_eq(101.sgn0(), 1);\n    }\n\n    #[test(should_fail_with = \"Field failed to decompose into specified 8 limbs\")]\n    fn test_bit_decomposition_overflow() {\n        // 8 bits can't represent large field values\n        let large_val = 0x1000000000000000;\n        let _: [u1; 8] = large_val.to_le_bits();\n    }\n\n    #[test(should_fail_with = \"Field failed to decompose into specified 4 limbs\")]\n    fn test_byte_decomposition_overflow() {\n        // 4 bytes can't represent large field values\n        let large_val = 0x1000000000000000;\n        let _: [u8; 4] = large_val.to_le_bytes();\n    }\n\n    #[test]\n    fn test_to_from_be_bytes_bn254_edge_cases() {\n        if crate::compat::is_bn254() {\n            // checking that decrementing this byte produces the expected 32 BE bytes for (modulus - 1)\n            let mut p_minus_1_bytes: [u8; 32] = modulus_be_bytes().as_array();\n            assert(p_minus_1_bytes[32 - 1] > 0);\n            p_minus_1_bytes[32 - 1] -= 1;\n\n            let p_minus_1 = Field::from_be_bytes::<32>(p_minus_1_bytes);\n            assert_eq(p_minus_1 + 1, 0);\n\n            // checking that converting (modulus - 1) from and then to 32 BE bytes produces the same bytes\n            let p_minus_1_converted_bytes: [u8; 32] = p_minus_1.to_be_bytes();\n            assert_eq(p_minus_1_converted_bytes, p_minus_1_bytes);\n\n            // checking that incrementing this byte produces 32 BE bytes for (modulus + 1)\n            let mut p_plus_1_bytes: [u8; 32] = modulus_be_bytes().as_array();\n            assert(p_plus_1_bytes[32 - 1] < 255);\n            p_plus_1_bytes[32 - 1] += 1;\n\n            let p_plus_1 = Field::from_be_bytes::<32>(p_plus_1_bytes);\n            assert_eq(p_plus_1, 1);\n\n            // checking that converting p_plus_1 to 32 BE bytes produces the same\n            // byte set to 1 as p_plus_1_bytes and otherwise zeroes\n            let mut p_plus_1_converted_bytes: [u8; 32] = p_plus_1.to_be_bytes();\n            assert_eq(p_plus_1_converted_bytes[32 - 1], 1);\n            p_plus_1_converted_bytes[32 - 1] = 0;\n            assert_eq(p_plus_1_converted_bytes, [0; 32]);\n\n            // checking that Field::from_be_bytes::<32> on the Field modulus produces 0\n            assert_eq(modulus_be_bytes().len(), 32);\n            let p = Field::from_be_bytes::<32>(modulus_be_bytes().as_array());\n            assert_eq(p, 0);\n\n            // checking that converting 0 to 32 BE bytes produces 32 zeroes\n            let p_bytes: [u8; 32] = 0.to_be_bytes();\n            assert_eq(p_bytes, [0; 32]);\n        }\n    }\n\n    #[test]\n    fn test_to_from_le_bytes_bn254_edge_cases() {\n        if crate::compat::is_bn254() {\n            // checking that decrementing this byte produces the expected 32 LE bytes for (modulus - 1)\n            let mut p_minus_1_bytes: [u8; 32] = modulus_le_bytes().as_array();\n            assert(p_minus_1_bytes[0] > 0);\n            p_minus_1_bytes[0] -= 1;\n\n            let p_minus_1 = Field::from_le_bytes::<32>(p_minus_1_bytes);\n            assert_eq(p_minus_1 + 1, 0);\n\n            // checking that converting (modulus - 1) from and then to 32 BE bytes produces the same bytes\n            let p_minus_1_converted_bytes: [u8; 32] = p_minus_1.to_le_bytes();\n            assert_eq(p_minus_1_converted_bytes, p_minus_1_bytes);\n\n            // checking that incrementing this byte produces 32 LE bytes for (modulus + 1)\n            let mut p_plus_1_bytes: [u8; 32] = modulus_le_bytes().as_array();\n            assert(p_plus_1_bytes[0] < 255);\n            p_plus_1_bytes[0] += 1;\n\n            let p_plus_1 = Field::from_le_bytes::<32>(p_plus_1_bytes);\n            assert_eq(p_plus_1, 1);\n\n            // checking that converting p_plus_1 to 32 LE bytes produces the same\n            // byte set to 1 as p_plus_1_bytes and otherwise zeroes\n            let mut p_plus_1_converted_bytes: [u8; 32] = p_plus_1.to_le_bytes();\n            assert_eq(p_plus_1_converted_bytes[0], 1);\n            p_plus_1_converted_bytes[0] = 0;\n            assert_eq(p_plus_1_converted_bytes, [0; 32]);\n\n            // checking that Field::from_le_bytes::<32> on the Field modulus produces 0\n            assert_eq(modulus_le_bytes().len(), 32);\n            let p = Field::from_le_bytes::<32>(modulus_le_bytes().as_array());\n            assert_eq(p, 0);\n\n            // checking that converting 0 to 32 LE bytes produces 32 zeroes\n            let p_bytes: [u8; 32] = 0.to_le_bytes();\n            assert_eq(p_bytes, [0; 32]);\n        }\n    }\n\n    /// Convert a little endian bit array to a field element.\n    /// If the provided bit array overflows the field modulus then the Field will silently wrap around.\n    fn from_le_bits<let N: u32>(bits: [u1; N]) -> Field {\n        static_assert(\n            N <= modulus_le_bits().len(),\n            \"N must be less than or equal to modulus_le_bits().len()\",\n        );\n        let mut v = 1;\n        let mut result = 0;\n\n        for i in 0..N {\n            result += (bits[i] as Field) * v;\n            v = v * 2;\n        }\n        result\n    }\n\n    /// Convert a big endian bit array to a field element.\n    /// If the provided bit array overflows the field modulus then the Field will silently wrap around.\n    fn from_be_bits<let N: u32>(bits: [u1; N]) -> Field {\n        let mut v = 1;\n        let mut result = 0;\n\n        for i in 0..N {\n            result += (bits[N - 1 - i] as Field) * v;\n            v = v * 2;\n        }\n        result\n    }\n\n    #[test]\n    fn test_to_from_be_bits_bn254_edge_cases() {\n        if crate::compat::is_bn254() {\n            // checking that decrementing this bit produces the expected 254 BE bits for (modulus - 1)\n            let mut p_minus_1_bits: [u1; 254] = modulus_be_bits().as_array();\n            assert(p_minus_1_bits[254 - 1] > 0);\n            p_minus_1_bits[254 - 1] -= 1;\n\n            let p_minus_1 = from_be_bits::<254>(p_minus_1_bits);\n            assert_eq(p_minus_1 + 1, 0);\n\n            // checking that converting (modulus - 1) from and then to 254 BE bits produces the same bits\n            let p_minus_1_converted_bits: [u1; 254] = p_minus_1.to_be_bits();\n            assert_eq(p_minus_1_converted_bits, p_minus_1_bits);\n\n            // checking that incrementing this bit produces 254 BE bits for (modulus + 4)\n            let mut p_plus_4_bits: [u1; 254] = modulus_be_bits().as_array();\n            assert(p_plus_4_bits[254 - 3] < 1);\n            p_plus_4_bits[254 - 3] += 1;\n\n            let p_plus_4 = from_be_bits::<254>(p_plus_4_bits);\n            assert_eq(p_plus_4, 4);\n\n            // checking that converting p_plus_4 to 254 BE bits produces the same\n            // bit set to 1 as p_plus_4_bits and otherwise zeroes\n            let mut p_plus_4_converted_bits: [u1; 254] = p_plus_4.to_be_bits();\n            assert_eq(p_plus_4_converted_bits[254 - 3], 1);\n            p_plus_4_converted_bits[254 - 3] = 0;\n            assert_eq(p_plus_4_converted_bits, [0; 254]);\n\n            // checking that Field::from_be_bits::<254> on the Field modulus produces 0\n            assert_eq(modulus_be_bits().len(), 254);\n            let p = from_be_bits::<254>(modulus_be_bits().as_array());\n            assert_eq(p, 0);\n\n            // checking that converting 0 to 254 BE bytes produces 254 zeroes\n            let p_bits: [u1; 254] = 0.to_be_bits();\n            assert_eq(p_bits, [0; 254]);\n        }\n    }\n\n    #[test]\n    fn test_to_from_le_bits_bn254_edge_cases() {\n        if crate::compat::is_bn254() {\n            // checking that decrementing this bit produces the expected 254 LE bits for (modulus - 1)\n            let mut p_minus_1_bits: [u1; 254] = modulus_le_bits().as_array();\n            assert(p_minus_1_bits[0] > 0);\n            p_minus_1_bits[0] -= 1;\n\n            let p_minus_1 = from_le_bits::<254>(p_minus_1_bits);\n            assert_eq(p_minus_1 + 1, 0);\n\n            // checking that converting (modulus - 1) from and then to 254 BE bits produces the same bits\n            let p_minus_1_converted_bits: [u1; 254] = p_minus_1.to_le_bits();\n            assert_eq(p_minus_1_converted_bits, p_minus_1_bits);\n\n            // checking that incrementing this bit produces 254 LE bits for (modulus + 4)\n            let mut p_plus_4_bits: [u1; 254] = modulus_le_bits().as_array();\n            assert(p_plus_4_bits[2] < 1);\n            p_plus_4_bits[2] += 1;\n\n            let p_plus_4 = from_le_bits::<254>(p_plus_4_bits);\n            assert_eq(p_plus_4, 4);\n\n            // checking that converting p_plus_4 to 254 LE bits produces the same\n            // bit set to 1 as p_plus_4_bits and otherwise zeroes\n            let mut p_plus_4_converted_bits: [u1; 254] = p_plus_4.to_le_bits();\n            assert_eq(p_plus_4_converted_bits[2], 1);\n            p_plus_4_converted_bits[2] = 0;\n            assert_eq(p_plus_4_converted_bits, [0; 254]);\n\n            // checking that Field::from_le_bits::<254> on the Field modulus produces 0\n            assert_eq(modulus_le_bits().len(), 254);\n            let p = from_le_bits::<254>(modulus_le_bits().as_array());\n            assert_eq(p, 0);\n\n            // checking that converting 0 to 254 LE bytes produces 254 zeroes\n            let p_bits: [u1; 254] = 0.to_le_bits();\n            assert_eq(p_bits, [0; 254]);\n        }\n    }\n}\n","path":"std/field/mod.nr"},"19":{"source":"// Exposed only for usage in `std::meta`\npub(crate) mod poseidon2;\n\nuse crate::default::Default;\nuse crate::embedded_curve_ops::{\n    EmbeddedCurvePoint, EmbeddedCurveScalar, multi_scalar_mul, multi_scalar_mul_array_return,\n};\nuse crate::meta::derive_via;\n\n#[foreign(sha256_compression)]\n// docs:start:sha256_compression\npub fn sha256_compression(input: [u32; 16], state: [u32; 8]) -> [u32; 8] {}\n// docs:end:sha256_compression\n\n#[foreign(keccakf1600)]\n// docs:start:keccakf1600\npub fn keccakf1600(input: [u64; 25]) -> [u64; 25] {}\n// docs:end:keccakf1600\n\npub mod keccak {\n    #[deprecated(\"This function has been moved to std::hash::keccakf1600\")]\n    pub fn keccakf1600(input: [u64; 25]) -> [u64; 25] {\n        super::keccakf1600(input)\n    }\n}\n\n#[foreign(blake2s)]\n// docs:start:blake2s\npub fn blake2s<let N: u32>(input: [u8; N]) -> [u8; 32]\n// docs:end:blake2s\n{}\n\n// docs:start:blake3\npub fn blake3<let N: u32>(input: [u8; N]) -> [u8; 32]\n// docs:end:blake3\n{\n    if crate::runtime::is_unconstrained() {\n        // Temporary measure while Barretenberg is main proving system.\n        // Please open an issue if you're working on another proving system and running into problems due to this.\n        crate::static_assert(\n            N <= 1024,\n            \"Barretenberg cannot prove blake3 hashes with inputs larger than 1024 bytes\",\n        );\n    }\n    __blake3(input)\n}\n\n#[foreign(blake3)]\nfn __blake3<let N: u32>(input: [u8; N]) -> [u8; 32] {}\n\n// docs:start:pedersen_commitment\npub fn pedersen_commitment<let N: u32>(input: [Field; N]) -> EmbeddedCurvePoint {\n    // docs:end:pedersen_commitment\n    pedersen_commitment_with_separator(input, 0)\n}\n\n#[inline_always]\npub fn pedersen_commitment_with_separator<let N: u32>(\n    input: [Field; N],\n    separator: u32,\n) -> EmbeddedCurvePoint {\n    let mut points = [EmbeddedCurveScalar { lo: 0, hi: 0 }; N];\n    for i in 0..N {\n        // we use the unsafe version because the multi_scalar_mul will constrain the scalars.\n        points[i] = from_field_unsafe(input[i]);\n    }\n    let generators = derive_generators(\"DEFAULT_DOMAIN_SEPARATOR\".as_bytes(), separator);\n    multi_scalar_mul(generators, points)\n}\n\n// docs:start:pedersen_hash\npub fn pedersen_hash<let N: u32>(input: [Field; N]) -> Field\n// docs:end:pedersen_hash\n{\n    pedersen_hash_with_separator(input, 0)\n}\n\n#[no_predicates]\npub fn pedersen_hash_with_separator<let N: u32>(input: [Field; N], separator: u32) -> Field {\n    let mut scalars: [EmbeddedCurveScalar; N + 1] = [EmbeddedCurveScalar { lo: 0, hi: 0 }; N + 1];\n    let mut generators: [EmbeddedCurvePoint; N + 1] =\n        [EmbeddedCurvePoint::point_at_infinity(); N + 1];\n    let domain_generators: [EmbeddedCurvePoint; N] =\n        derive_generators(\"DEFAULT_DOMAIN_SEPARATOR\".as_bytes(), separator);\n\n    for i in 0..N {\n        scalars[i] = from_field_unsafe(input[i]);\n        generators[i] = domain_generators[i];\n    }\n    scalars[N] = EmbeddedCurveScalar { lo: N as Field, hi: 0 as Field };\n\n    let length_generator: [EmbeddedCurvePoint; 1] =\n        derive_generators(\"pedersen_hash_length\".as_bytes(), 0);\n    generators[N] = length_generator[0];\n    multi_scalar_mul_array_return(generators, scalars, true)[0].x\n}\n\n#[field(bn254)]\n#[inline_always]\npub fn derive_generators<let N: u32, let M: u32>(\n    domain_separator_bytes: [u8; M],\n    starting_index: u32,\n) -> [EmbeddedCurvePoint; N] {\n    crate::assert_constant(domain_separator_bytes);\n    // TODO(https://github.com/noir-lang/noir/issues/5672): Add back assert_constant on starting_index\n    __derive_generators(domain_separator_bytes, starting_index)\n}\n\n#[builtin(derive_pedersen_generators)]\n#[field(bn254)]\nfn __derive_generators<let N: u32, let M: u32>(\n    domain_separator_bytes: [u8; M],\n    starting_index: u32,\n) -> [EmbeddedCurvePoint; N] {}\n\n#[field(bn254)]\n// Decompose the input 'bn254 scalar' into two 128 bits limbs.\n// It is called 'unsafe' because it does not assert the limbs are 128 bits\n// Assuming the limbs are 128 bits:\n// Assert the decomposition does not overflow the field size.\nfn from_field_unsafe(scalar: Field) -> EmbeddedCurveScalar {\n    // Safety: xlo and xhi decomposition is checked below\n    let (xlo, xhi) = unsafe { crate::field::bn254::decompose_hint(scalar) };\n    // Check that the decomposition is correct\n    assert_eq(scalar, xlo + crate::field::bn254::TWO_POW_128 * xhi);\n    // Check that the decomposition does not overflow the field size\n    let (a, b) = if xhi == crate::field::bn254::PHI {\n        (xlo, crate::field::bn254::PLO)\n    } else {\n        (xhi, crate::field::bn254::PHI)\n    };\n    crate::field::bn254::assert_lt(a, b);\n\n    EmbeddedCurveScalar { lo: xlo, hi: xhi }\n}\n\npub fn poseidon2_permutation<let N: u32>(input: [Field; N], state_len: u32) -> [Field; N] {\n    assert_eq(input.len(), state_len);\n    poseidon2_permutation_internal(input)\n}\n\n#[foreign(poseidon2_permutation)]\nfn poseidon2_permutation_internal<let N: u32>(input: [Field; N]) -> [Field; N] {}\n\n// Generic hashing support.\n// Partially ported and impacted by rust.\n\n// Hash trait shall be implemented per type.\n#[derive_via(derive_hash)]\npub trait Hash {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher;\n}\n\n// docs:start:derive_hash\ncomptime fn derive_hash(s: TypeDefinition) -> Quoted {\n    let name = quote { $crate::hash::Hash };\n    let signature = quote { fn hash<H>(_self: Self, _state: &mut H) where H: $crate::hash::Hasher };\n    let for_each_field = |name| quote { _self.$name.hash(_state); };\n    crate::meta::make_trait_impl(\n        s,\n        name,\n        signature,\n        for_each_field,\n        quote {},\n        |fields| fields,\n    )\n}\n// docs:end:derive_hash\n\n// Hasher trait shall be implemented by algorithms to provide hash-agnostic means.\n// TODO: consider making the types generic here ([u8], [Field], etc.)\npub trait Hasher {\n    fn finish(self) -> Field;\n\n    fn write(&mut self, input: Field);\n}\n\n// BuildHasher is a factory trait, responsible for production of specific Hasher.\npub trait BuildHasher {\n    type H: Hasher;\n\n    fn build_hasher(self) -> H;\n}\n\npub struct BuildHasherDefault<H>;\n\nimpl<H> BuildHasher for BuildHasherDefault<H>\nwhere\n    H: Hasher + Default,\n{\n    type H = H;\n\n    fn build_hasher(_self: Self) -> H {\n        H::default()\n    }\n}\n\nimpl<H> Default for BuildHasherDefault<H>\nwhere\n    H: Hasher + Default,\n{\n    fn default() -> Self {\n        BuildHasherDefault {}\n    }\n}\n\nimpl Hash for Field {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self);\n    }\n}\n\nimpl Hash for u1 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u8 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u16 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u32 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u64 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u128 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for i8 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as u8 as Field);\n    }\n}\n\nimpl Hash for i16 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as u16 as Field);\n    }\n}\n\nimpl Hash for i32 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as u32 as Field);\n    }\n}\n\nimpl Hash for i64 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as u64 as Field);\n    }\n}\n\nimpl Hash for bool {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for () {\n    fn hash<H>(_self: Self, _state: &mut H)\n    where\n        H: Hasher,\n    {}\n}\n\nimpl<T, let N: u32> Hash for [T; N]\nwhere\n    T: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        for elem in self {\n            elem.hash(state);\n        }\n    }\n}\n\nimpl<T> Hash for [T]\nwhere\n    T: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.len().hash(state);\n        for elem in self {\n            elem.hash(state);\n        }\n    }\n}\n\nimpl<A, B> Hash for (A, B)\nwhere\n    A: Hash,\n    B: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.0.hash(state);\n        self.1.hash(state);\n    }\n}\n\nimpl<A, B, C> Hash for (A, B, C)\nwhere\n    A: Hash,\n    B: Hash,\n    C: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.0.hash(state);\n        self.1.hash(state);\n        self.2.hash(state);\n    }\n}\n\nimpl<A, B, C, D> Hash for (A, B, C, D)\nwhere\n    A: Hash,\n    B: Hash,\n    C: Hash,\n    D: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.0.hash(state);\n        self.1.hash(state);\n        self.2.hash(state);\n        self.3.hash(state);\n    }\n}\n\nimpl<A, B, C, D, E> Hash for (A, B, C, D, E)\nwhere\n    A: Hash,\n    B: Hash,\n    C: Hash,\n    D: Hash,\n    E: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.0.hash(state);\n        self.1.hash(state);\n        self.2.hash(state);\n        self.3.hash(state);\n        self.4.hash(state);\n    }\n}\n\n// Some test vectors for Pedersen hash and Pedersen Commitment.\n// They have been generated using the same functions so the tests are for now useless\n// but they will be useful when we switch to Noir implementation.\n#[test]\nfn assert_pedersen() {\n    assert_eq(\n        pedersen_hash_with_separator([1], 1),\n        0x1b3f4b1a83092a13d8d1a59f7acb62aba15e7002f4440f2275edb99ebbc2305f,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1], 1),\n        EmbeddedCurvePoint {\n            x: 0x054aa86a73cb8a34525e5bbed6e43ba1198e860f5f3950268f71df4591bde402,\n            y: 0x209dcfbf2cfb57f9f6046f44d71ac6faf87254afc7407c04eb621a6287cac126,\n            is_infinite: false,\n        },\n    );\n\n    assert_eq(\n        pedersen_hash_with_separator([1, 2], 2),\n        0x26691c129448e9ace0c66d11f0a16d9014a9e8498ee78f4d69f0083168188255,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2], 2),\n        EmbeddedCurvePoint {\n            x: 0x2e2b3b191e49541fe468ec6877721d445dcaffe41728df0a0eafeb15e87b0753,\n            y: 0x2ff4482400ad3a6228be17a2af33e2bcdf41be04795f9782bd96efe7e24f8778,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3], 3),\n        0x0bc694b7a1f8d10d2d8987d07433f26bd616a2d351bc79a3c540d85b6206dbe4,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3], 3),\n        EmbeddedCurvePoint {\n            x: 0x1fee4e8cf8d2f527caa2684236b07c4b1bad7342c01b0f75e9a877a71827dc85,\n            y: 0x2f9fedb9a090697ab69bf04c8bc15f7385b3e4b68c849c1536e5ae15ff138fd1,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4], 4),\n        0xdae10fb32a8408521803905981a2b300d6a35e40e798743e9322b223a5eddc,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4], 4),\n        EmbeddedCurvePoint {\n            x: 0x07ae3e202811e1fca39c2d81eabe6f79183978e6f12be0d3b8eda095b79bdbc9,\n            y: 0x0afc6f892593db6fbba60f2da558517e279e0ae04f95758587760ba193145014,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5], 5),\n        0xfc375b062c4f4f0150f7100dfb8d9b72a6d28582dd9512390b0497cdad9c22,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5], 5),\n        EmbeddedCurvePoint {\n            x: 0x1754b12bd475a6984a1094b5109eeca9838f4f81ac89c5f0a41dbce53189bb29,\n            y: 0x2da030e3cfcdc7ddad80eaf2599df6692cae0717d4e9f7bfbee8d073d5d278f7,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6], 6),\n        0x1696ed13dc2730062a98ac9d8f9de0661bb98829c7582f699d0273b18c86a572,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6], 6),\n        EmbeddedCurvePoint {\n            x: 0x190f6c0e97ad83e1e28da22a98aae156da083c5a4100e929b77e750d3106a697,\n            y: 0x1f4b60f34ef91221a0b49756fa0705da93311a61af73d37a0c458877706616fb,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7], 7),\n        0x128c0ff144fc66b6cb60eeac8a38e23da52992fc427b92397a7dffd71c45ede3,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7], 7),\n        EmbeddedCurvePoint {\n            x: 0x015441e9d29491b06563fac16fc76abf7a9534c715421d0de85d20dbe2965939,\n            y: 0x1d2575b0276f4e9087e6e07c2cb75aa1baafad127af4be5918ef8a2ef2fea8fc,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7, 8], 8),\n        0x2f960e117482044dfc99d12fece2ef6862fba9242be4846c7c9a3e854325a55c,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7, 8], 8),\n        EmbeddedCurvePoint {\n            x: 0x1657737676968887fceb6dd516382ea13b3a2c557f509811cd86d5d1199bc443,\n            y: 0x1f39f0cb569040105fa1e2f156521e8b8e08261e635a2b210bdc94e8d6d65f77,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9], 9),\n        0x0c96db0790602dcb166cc4699e2d306c479a76926b81c2cb2aaa92d249ec7be7,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9], 9),\n        EmbeddedCurvePoint {\n            x: 0x0a3ceae42d14914a432aa60ec7fded4af7dad7dd4acdbf2908452675ec67e06d,\n            y: 0xfc19761eaaf621ad4aec9a8b2e84a4eceffdba78f60f8b9391b0bd9345a2f2,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 10),\n        0x2cd37505871bc460a62ea1e63c7fe51149df5d0801302cf1cbc48beb8dff7e94,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 10),\n        EmbeddedCurvePoint {\n            x: 0x2fb3f8b3d41ddde007c8c3c62550f9a9380ee546fcc639ffbb3fd30c8d8de30c,\n            y: 0x300783be23c446b11a4c0fabf6c91af148937cea15fcf5fb054abf7f752ee245,\n            is_infinite: false,\n        },\n    );\n}\n","path":"std/hash/mod.nr"},"51":{"source":"// Claim V2 Circuit - Ownership Proof with Grumpkin ECDH (SHIELDED-ONLY)\n//\n// This is the core ownership proof circuit for the dual-key ECDH system.\n// It proves that the claimer knows the spending private key that corresponds\n// to the stealth deposit.\n//\n// SHIELDED-ONLY ARCHITECTURE:\n// - Amount is PRIVATE (not a public input)\n// - Amount is only revealed at withdrawal time (unavoidable for BTC)\n// - This provides maximum privacy for transfers/splits\n//\n// Key Security Properties:\n// - Sender knows: ephemeral_priv, shared_secret, commitment\n// - Sender does NOT know: recipient's spending_priv\n// - Nullifier = H(spending_priv, leaf_index, DOMAIN_NULL)\n// - Only recipient can compute valid nullifier!\n//\n// SECURITY IMPROVEMENTS (V2 Simplified):\n// - Removed random field: ephemeral key uniqueness is sufficient\n// - Removed double nullifier hashing: saves ~1.5k constraints\n// - Commitment: Poseidon2(notePubKey, amount) instead of (notePubKey, amount, random)\n// - Public input: nullifier directly (not hash of nullifier)\n// - Amount is private witness only (shielded-only architecture)\n//\n// If sender tries with wrong key:\n//   wrong_shared = ECDH(sender_priv, ephemeral_pub)\n//   wrong_note_pk = H(wrong_shared)\n//   wrong_commitment = H(wrong_note_pk, amount)\n//   NOT IN MERKLE TREE -> Proof fails\n//\n// Constraint Cost: ~8.5k total (saved ~1.5k from removing double hash)\n// - Grumpkin ECDH: ~2k\n// - Poseidon2 hashes: ~500 (reduced from ~1.5k)\n// - Merkle proof (20 levels): ~6k\n\nuse dep::zvault_utils::grumpkin;\nuse dep::poseidon::poseidon2::Poseidon2;\n\nfn main(\n    // PRIVATE INPUTS (never revealed)\n    // Grumpkin spending private key (scalar field element)\n    spending_priv: Field,\n    // Sender's ephemeral Grumpkin public key (x-coordinate)\n    ephemeral_spend_pub_x: Field,\n    // Sender's ephemeral Grumpkin public key (y-coordinate)\n    ephemeral_spend_pub_y: Field,\n    // Note amount in satoshis (PRIVATE - shielded-only architecture)\n    // Amount is never revealed except at withdrawal time\n    amount: Field,\n    // Merkle tree leaf index\n    leaf_index: Field,\n    // Merkle path elements (siblings)\n    merkle_path: [Field; 20],\n    // Merkle path indices (0 = left, 1 = right)\n    merkle_indices: [u1; 20],\n    // PUBLIC INPUTS (verified on-chain)\n    // Current Merkle root\n    merkle_root: pub Field,\n    // Nullifier (for double-spend prevention) - SIMPLIFIED: no hash wrapper\n    nullifier_pub: pub Field,\n    // NOTE: amount_pub removed in shielded-only architecture\n    // Amount is only revealed at withdrawal time (unavoidable for BTC)\n) {\n    // 1. GRUMPKIN ECDH (Efficient! ~2k constraints)\n    // Convert spending key to scalar\n    let spending_scalar = grumpkin::scalar_from_field(spending_priv);\n\n    // Parse ephemeral public key\n    let ephemeral_pub = grumpkin::point_from_coords(\n        ephemeral_spend_pub_x,\n        ephemeral_spend_pub_y\n    );\n\n    // Perform ECDH to get shared secret\n    let (shared_x, shared_y) = grumpkin::ecdh(spending_scalar, ephemeral_pub);\n\n    // 2. DERIVE NOTE PUBLIC KEY\n    // notePubKey = Poseidon2(shared_x, shared_y, DOMAIN_NPK)\n    let note_pub_key = grumpkin::derive_note_pubkey(shared_x, shared_y);\n\n    // 3. COMPUTE AND VERIFY COMMITMENT (SIMPLIFIED: no random)\n    // commitment = Poseidon2(notePubKey, amount)\n    // Note: Pass 0 for random to use simplified V2 formula\n    let commitment = grumpkin::compute_commitment_v2(note_pub_key, amount, 0);\n\n    // 4. VERIFY COMMITMENT EXISTS IN MERKLE TREE\n    let computed_root = compute_merkle_root_20(\n        commitment,\n        leaf_index,\n        merkle_path,\n        merkle_indices\n    );\n    assert(merkle_root == computed_root, \"Commitment not in Merkle tree\");\n\n    // 5. COMPUTE AND VERIFY NULLIFIER (OWNERSHIP PROOF!)\n    // CRITICAL: Nullifier is derived from SPENDING PRIVATE KEY + leaf index\n    // Only the legitimate recipient can compute this!\n    // Sender knows shared secret but NOT spending_priv\n    //\n    // SIMPLIFIED: Single hash, no double-hashing (saves ~1.5k constraints)\n    // nullifier = Poseidon2(spending_priv, leaf_index, DOMAIN_NULL)\n    let nullifier = grumpkin::compute_nullifier_v2(spending_priv, leaf_index);\n\n    // Direct comparison (no hash wrapper)\n    assert(nullifier_pub == nullifier, \"Invalid nullifier\");\n\n    // NOTE: Amount verification removed in shielded-only architecture\n    // Amount stays private - only verified via commitment in Merkle tree\n    // Amount is revealed only at withdrawal time (unavoidable for BTC)\n}\n\n// Compute Merkle root from leaf and path (20-level tree)\nfn compute_merkle_root_20(\n    leaf: Field,\n    leaf_index: Field,\n    path_elements: [Field; 20],\n    path_indices: [u1; 20]\n) -> Field {\n    let mut current = leaf;\n\n    // Verify leaf index matches path indices\n    let mut computed_index: Field = 0;\n    let mut multiplier: Field = 1;\n    for i in 0..20 {\n        if path_indices[i] == 1 {\n            computed_index += multiplier;\n        }\n        multiplier *= 2;\n    }\n    assert(leaf_index == computed_index, \"Leaf index mismatch\");\n\n    // Compute root\n    for i in 0..20 {\n        let sibling = path_elements[i];\n        let is_right = (path_indices[i] == 1) as bool;\n\n        let (left, right) = if is_right {\n            (sibling, current)\n        } else {\n            (current, sibling)\n        };\n\n        current = Poseidon2::hash([left, right], 2);\n    }\n\n    current\n}\n\n// Tests\n\n#[test]\nfn test_claim_v2_basic() {\n    // Generate test keypairs\n    let spending_priv = 12345;\n    let spending_scalar = grumpkin::scalar_from_field(spending_priv);\n    let spending_pub = grumpkin::derive_pubkey(spending_scalar);\n\n    let ephemeral_priv = 67890;\n    let ephemeral_scalar = grumpkin::scalar_from_field(ephemeral_priv);\n    let ephemeral_pub = grumpkin::derive_pubkey(ephemeral_scalar);\n\n    let amount = 100000;\n    let leaf_index = 0;\n\n    // Sender computes commitment (SIMPLIFIED: no random)\n    let (sender_shared_x, sender_shared_y) = grumpkin::ecdh(ephemeral_scalar, spending_pub);\n    let sender_npk = grumpkin::derive_note_pubkey(sender_shared_x, sender_shared_y);\n    let commitment = grumpkin::compute_commitment_v2(sender_npk, amount, 0);\n\n    // Compute nullifier (recipient would do this)\n    // SIMPLIFIED: nullifier is used directly, no hash wrapper\n    let nullifier = grumpkin::compute_nullifier_v2(spending_priv, leaf_index);\n\n    // Build Merkle tree with single leaf\n    let zero: Field = 0;\n    let merkle_path: [Field; 20] = [zero; 20];\n    let path_indices: [u1; 20] = [0; 20];\n\n    // Compute root (all siblings are zero)\n    let mut current = commitment;\n    for _i in 0..20 {\n        current = Poseidon2::hash([current, zero], 2);\n    }\n    let merkle_root = current;\n\n    // Run the circuit (shielded-only: no amount_pub)\n    main(\n        spending_priv,\n        ephemeral_pub.x,\n        ephemeral_pub.y,\n        amount,\n        leaf_index,\n        merkle_path,\n        path_indices,\n        merkle_root,\n        nullifier\n    );\n}\n\n#[test(should_fail_with = \"Commitment not in Merkle tree\")]\nfn test_claim_v2_wrong_spending_key() {\n    // This test proves that sender CANNOT claim recipient's funds\n\n    // Recipient's keys\n    let spending_priv = 12345;\n    let spending_scalar = grumpkin::scalar_from_field(spending_priv);\n    let spending_pub = grumpkin::derive_pubkey(spending_scalar);\n\n    // Sender's ephemeral keys\n    let ephemeral_priv = 67890;\n    let ephemeral_scalar = grumpkin::scalar_from_field(ephemeral_priv);\n    let ephemeral_pub = grumpkin::derive_pubkey(ephemeral_scalar);\n\n    let amount = 100000;\n    let leaf_index = 0;\n\n    // Sender computes commitment (correctly, no random in V2)\n    let (sender_shared_x, sender_shared_y) = grumpkin::ecdh(ephemeral_scalar, spending_pub);\n    let sender_npk = grumpkin::derive_note_pubkey(sender_shared_x, sender_shared_y);\n    let commitment = grumpkin::compute_commitment_v2(sender_npk, amount, 0);\n\n    // Sender builds Merkle tree with correct commitment\n    let zero: Field = 0;\n    let merkle_path: [Field; 20] = [zero; 20];\n    let path_indices: [u1; 20] = [0; 20];\n\n    let mut current = commitment;\n    for _i in 0..20 {\n        current = Poseidon2::hash([current, zero], 2);\n    }\n    let merkle_root = current;\n\n    // Sender tries to claim with their own key (wrong!)\n    let attacker_priv = 11111; // Different from spending_priv\n\n    // Attacker computes their own (wrong) nullifier\n    let attacker_nullifier = grumpkin::compute_nullifier_v2(attacker_priv, leaf_index);\n\n    // This should FAIL because attacker's ECDH produces wrong commitment\n    main(\n        attacker_priv,\n        ephemeral_pub.x,\n        ephemeral_pub.y,\n        amount,\n        leaf_index,\n        merkle_path,\n        path_indices,\n        merkle_root,\n        attacker_nullifier\n    );\n}\n\n#[test(should_fail_with = \"Invalid nullifier\")]\nfn test_claim_v2_wrong_nullifier() {\n    // Recipient tries to use wrong nullifier\n    let spending_priv = 12345;\n    let spending_scalar = grumpkin::scalar_from_field(spending_priv);\n    let spending_pub = grumpkin::derive_pubkey(spending_scalar);\n\n    let ephemeral_priv = 67890;\n    let ephemeral_scalar = grumpkin::scalar_from_field(ephemeral_priv);\n    let ephemeral_pub = grumpkin::derive_pubkey(ephemeral_scalar);\n\n    let amount = 100000;\n    let leaf_index = 0;\n\n    // Compute correct commitment (no random in V2)\n    let (sender_shared_x, sender_shared_y) = grumpkin::ecdh(ephemeral_scalar, spending_pub);\n    let sender_npk = grumpkin::derive_note_pubkey(sender_shared_x, sender_shared_y);\n    let commitment = grumpkin::compute_commitment_v2(sender_npk, amount, 0);\n\n    // Build Merkle tree\n    let zero: Field = 0;\n    let merkle_path: [Field; 20] = [zero; 20];\n    let path_indices: [u1; 20] = [0; 20];\n\n    let mut current = commitment;\n    for _i in 0..20 {\n        current = Poseidon2::hash([current, zero], 2);\n    }\n    let merkle_root = current;\n\n    // Use wrong nullifier (not the correct one for this spending_priv + leaf_index)\n    let wrong_nullifier = 123456789;\n\n    // This should FAIL because nullifier doesn't match\n    main(\n        spending_priv,\n        ephemeral_pub.x,\n        ephemeral_pub.y,\n        amount,\n        leaf_index,\n        merkle_path,\n        path_indices,\n        merkle_root,\n        wrong_nullifier\n    );\n}\n","path":"/Users/chengchunyuan/project/hackathon/zVault/noir-circuits/claim_v2/src/main.nr"},"58":{"source":"use std::default::Default;\nuse std::hash::Hasher;\n\ncomptime global RATE: u32 = 3;\n\npub struct Poseidon2 {\n    cache: [Field; 3],\n    state: [Field; 4],\n    cache_size: u32,\n    squeeze_mode: bool, // 0 => absorb, 1 => squeeze\n}\n\nimpl Poseidon2 {\n    #[no_predicates]\n    pub fn hash<let N: u32>(input: [Field; N], message_size: u32) -> Field {\n        Poseidon2::hash_internal(input, message_size, message_size != N)\n    }\n\n    pub(crate) fn new(iv: Field) -> Poseidon2 {\n        let mut result =\n            Poseidon2 { cache: [0; 3], state: [0; 4], cache_size: 0, squeeze_mode: false };\n        result.state[RATE] = iv;\n        result\n    }\n\n    fn perform_duplex(&mut self) {\n        // add the cache into sponge state\n        for i in 0..RATE {\n            // We effectively zero-pad the cache by only adding to the state\n            // cache that is less than the specified `cache_size`\n            if i < self.cache_size {\n                self.state[i] += self.cache[i];\n            }\n        }\n        self.state = crate::poseidon2_permutation(self.state, 4);\n    }\n\n    fn absorb(&mut self, input: Field) {\n        assert(!self.squeeze_mode);\n        if self.cache_size == RATE {\n            // If we're absorbing, and the cache is full, apply the sponge permutation to compress the cache\n            self.perform_duplex();\n            self.cache[0] = input;\n            self.cache_size = 1;\n        } else {\n            // If we're absorbing, and the cache is not full, add the input into the cache\n            self.cache[self.cache_size] = input;\n            self.cache_size += 1;\n        }\n    }\n\n    fn squeeze(&mut self) -> Field {\n        assert(!self.squeeze_mode);\n        // If we're in absorb mode, apply sponge permutation to compress the cache.\n        self.perform_duplex();\n        self.squeeze_mode = true;\n\n        // Pop one item off the top of the permutation and return it.\n        self.state[0]\n    }\n\n    fn hash_internal<let N: u32>(\n        input: [Field; N],\n        in_len: u32,\n        is_variable_length: bool,\n    ) -> Field {\n        let two_pow_64 = 18446744073709551616;\n        let iv: Field = (in_len as Field) * two_pow_64;\n        let mut sponge = Poseidon2::new(iv);\n        for i in 0..input.len() {\n            if i < in_len {\n                sponge.absorb(input[i]);\n            }\n        }\n\n        // In the case where the hash preimage is variable-length, we append `1` to the end of the input, to distinguish\n        // from fixed-length hashes. (the combination of this additional field element + the hash IV ensures\n        // fixed-length and variable-length hashes do not collide)\n        if is_variable_length {\n            sponge.absorb(1);\n        }\n        sponge.squeeze()\n    }\n}\n\npub struct Poseidon2Hasher {\n    _state: [Field],\n}\n\nimpl Hasher for Poseidon2Hasher {\n    fn finish(self) -> Field {\n        let iv: Field = (self._state.len() as Field) * 18446744073709551616; // iv = (self._state.len() << 64)\n        let mut sponge = Poseidon2::new(iv);\n        for i in 0..self._state.len() {\n            sponge.absorb(self._state[i]);\n        }\n        sponge.squeeze()\n    }\n\n    fn write(&mut self, input: Field) {\n        self._state = self._state.push_back(input);\n    }\n}\n\nimpl Default for Poseidon2Hasher {\n    fn default() -> Self {\n        Poseidon2Hasher { _state: &[] }\n    }\n}\n","path":"/Users/chengchunyuan/nargo/github.com/noir-lang/poseidon/v0.1.1/src/poseidon2.nr"},"60":{"source":"/**\n * Grumpkin Curve ECDH Operations for zVault\n *\n * Grumpkin is Noir's embedded curve - extremely efficient for in-circuit operations.\n * ~2k constraints for ECDH vs ~300k for X25519/Ed25519.\n *\n * This module provides:\n * - ECDH key exchange for spending proofs\n * - Note public key derivation\n * - Nullifier computation from spending key + leaf index\n */\n\nuse std::embedded_curve_ops::{\n    EmbeddedCurvePoint,\n    EmbeddedCurveScalar,\n    embedded_curve_add,\n    multi_scalar_mul,\n};\nuse dep::poseidon::poseidon2::Poseidon2;\n\n// Domain separators\nglobal DOMAIN_NPK: Field = 0x6e706b;     // \"npk\" - note public key\nglobal DOMAIN_NULL: Field = 0x6e756c6c; // \"null\" - nullifier\n\n/**\n * Grumpkin generator point (standard)\n */\npub fn generator() -> EmbeddedCurvePoint {\n    EmbeddedCurvePoint {\n        x: 1,\n        y: 17631683881184975370165255887551781615748388533673675138860,\n        is_infinite: false,\n    }\n}\n\n/**\n * Perform ECDH key exchange on Grumpkin curve\n *\n * shared_point = priv_key * pub_key\n *\n * Returns (shared_x, shared_y) for use in key derivation.\n *\n * @param priv_key - Private key as scalar\n * @param pub_key - Public key as curve point\n * @returns Tuple of (x, y) coordinates of shared point\n */\npub fn ecdh(\n    priv_key: EmbeddedCurveScalar,\n    pub_key: EmbeddedCurvePoint\n) -> (Field, Field) {\n    // Use multi_scalar_mul for efficient scalar multiplication\n    let shared_point = multi_scalar_mul([pub_key], [priv_key]);\n\n    // Return coordinates (handle point at infinity)\n    assert(!shared_point.is_infinite, \"ECDH resulted in point at infinity\");\n\n    (shared_point.x, shared_point.y)\n}\n\n/**\n * Derive note public key from ECDH shared secret\n *\n * notePubKey = Poseidon2(shared_x, shared_y, DOMAIN_NPK)\n *\n * This is the core of ownership proof - only the recipient\n * with the correct spending key can derive the same notePubKey.\n */\npub fn derive_note_pubkey(shared_x: Field, shared_y: Field) -> Field {\n    Poseidon2::hash([shared_x, shared_y, DOMAIN_NPK], 3)\n}\n\n/**\n * Compute commitment from note public key and amount (SIMPLIFIED)\n *\n * commitment = Poseidon2(notePubKey, amount)\n *\n * SECURITY NOTE: Random field removed - ephemeral key uniqueness is sufficient.\n * Each deposit uses a fresh ephemeral keypair, so notePubKey is already unique.\n *\n * For backward compatibility, if random != 0, use the old formula.\n */\npub fn compute_commitment_v2(note_pubkey: Field, amount: Field, random: Field) -> Field {\n    if random == 0 {\n        // V2 simplified: no random\n        Poseidon2::hash([note_pubkey, amount], 2)\n    } else {\n        // V1 legacy: with random\n        Poseidon2::hash([note_pubkey, amount, random], 3)\n    }\n}\n\n/**\n * Compute nullifier from spending private key and leaf index\n *\n * CRITICAL: This is what prevents sender from claiming recipient's funds.\n * - Sender knows: ephemeral_priv, shared_secret\n * - Sender does NOT know: recipient's spending_priv\n * - Only recipient can compute valid nullifier\n *\n * nullifier = Poseidon2(spending_priv, leaf_index, DOMAIN_NULL)\n */\npub fn compute_nullifier_v2(spending_priv: Field, leaf_index: Field) -> Field {\n    Poseidon2::hash([spending_priv, leaf_index, DOMAIN_NULL], 3)\n}\n\n/**\n * Hash nullifier for public input\n *\n * NOTE: This function is DEPRECATED in V2 simplified format.\n * The nullifier itself is now used as the public input directly.\n * Double-hashing provided no security benefit (nullifier is already\n * a secure hash of spending_priv + leaf_index + domain separator).\n *\n * This function is kept for backward compatibility with V1.\n *\n * nullifier_hash = Poseidon2(nullifier)\n */\npub fn hash_nullifier(nullifier: Field) -> Field {\n    Poseidon2::hash([nullifier], 1)\n}\n\n/**\n * Create a scalar from a field element\n *\n * Used to convert spending private key to scalar for ECDH.\n */\npub fn scalar_from_field(f: Field) -> EmbeddedCurveScalar {\n    EmbeddedCurveScalar::from_field(f)\n}\n\n/**\n * Create a point from x and y coordinates\n */\npub fn point_from_coords(x: Field, y: Field) -> EmbeddedCurvePoint {\n    EmbeddedCurvePoint { x, y, is_infinite: false }\n}\n\n/**\n * Derive public key from private key\n *\n * pub_key = priv_key * G\n */\npub fn derive_pubkey(priv_key: EmbeddedCurveScalar) -> EmbeddedCurvePoint {\n    multi_scalar_mul([generator()], [priv_key])\n}\n\n/**\n * Verify a point is not at infinity\n */\npub fn is_valid_point(point: EmbeddedCurvePoint) -> bool {\n    !point.is_infinite\n}\n\n// ============================================================================\n// V2 Claim Circuit Helpers\n// ============================================================================\n\n/**\n * Full V2 claim verification flow (SIMPLIFIED)\n *\n * 1. Perform Grumpkin ECDH\n * 2. Derive note public key\n * 3. Compute commitment (no random in V2)\n * 4. Verify commitment in Merkle tree\n * 5. Compute nullifier (single hash, no double-hashing)\n *\n * @param spending_priv - Recipient's spending private key\n * @param ephemeral_spend_pub - Sender's ephemeral Grumpkin pubkey\n * @param amount - Note amount\n * @param random - Random value (pass 0 for V2 simplified format)\n * @param leaf_index - Merkle tree leaf index\n * @returns (commitment, nullifier, nullifier_hash_deprecated)\n */\npub fn verify_ownership(\n    spending_priv: Field,\n    ephemeral_spend_pub_x: Field,\n    ephemeral_spend_pub_y: Field,\n    amount: Field,\n    random: Field,\n    leaf_index: Field\n) -> (Field, Field, Field) {\n    // 1. Convert spending key to scalar\n    let spending_scalar = scalar_from_field(spending_priv);\n\n    // 2. Parse ephemeral public key\n    let ephemeral_pub = point_from_coords(ephemeral_spend_pub_x, ephemeral_spend_pub_y);\n\n    // 3. Perform Grumpkin ECDH\n    let (shared_x, shared_y) = ecdh(spending_scalar, ephemeral_pub);\n\n    // 4. Derive note public key\n    let note_pubkey = derive_note_pubkey(shared_x, shared_y);\n\n    // 5. Compute commitment (uses random=0 for V2 simplified)\n    let commitment = compute_commitment_v2(note_pubkey, amount, random);\n\n    // 6. Compute nullifier (only recipient can do this!)\n    let nullifier = compute_nullifier_v2(spending_priv, leaf_index);\n\n    // Note: nullifier_hash is deprecated in V2, but kept for backward compatibility\n    let nullifier_hash = hash_nullifier(nullifier);\n\n    (commitment, nullifier, nullifier_hash)\n}\n\n// ============================================================================\n// Tests\n// ============================================================================\n\n#[test]\nfn test_ecdh() {\n    // Test with known values\n    let priv_key = scalar_from_field(12345);\n    let pub_key = derive_pubkey(scalar_from_field(67890));\n\n    let (x, y) = ecdh(priv_key, pub_key);\n\n    // Just verify we get a result (not infinity)\n    assert(x != 0);\n}\n\n#[test]\nfn test_note_pubkey_derivation() {\n    let shared_x = 12345;\n    let shared_y = 67890;\n\n    let npk = derive_note_pubkey(shared_x, shared_y);\n\n    // Should produce a valid field element\n    assert(npk != 0);\n}\n\n#[test]\nfn test_nullifier_derivation() {\n    let spending_priv = 12345;\n    let leaf_index = 0;\n\n    let nullifier = compute_nullifier_v2(spending_priv, leaf_index);\n    let nullifier_hash = hash_nullifier(nullifier);\n\n    // Different leaf indices should produce different nullifiers\n    let nullifier2 = compute_nullifier_v2(spending_priv, 1);\n    assert(nullifier != nullifier2);\n\n    // Same inputs should produce same nullifier\n    let nullifier3 = compute_nullifier_v2(spending_priv, leaf_index);\n    assert(nullifier == nullifier3);\n}\n\n#[test]\nfn test_verify_ownership() {\n    // Generate test keypairs\n    let spending_priv = 12345;\n    let spending_scalar = scalar_from_field(spending_priv);\n    let spending_pub = derive_pubkey(spending_scalar);\n\n    let ephemeral_priv = 67890;\n    let ephemeral_scalar = scalar_from_field(ephemeral_priv);\n    let ephemeral_pub = derive_pubkey(ephemeral_scalar);\n\n    let amount = 100000;\n    let random = 999999;\n    let leaf_index = 0;\n\n    // Simulate sender computing shared secret\n    let (sender_shared_x, sender_shared_y) = ecdh(ephemeral_scalar, spending_pub);\n    let sender_npk = derive_note_pubkey(sender_shared_x, sender_shared_y);\n    let sender_commitment = compute_commitment_v2(sender_npk, amount, random);\n\n    // Recipient verifies ownership\n    let (commitment, _nullifier, _nullifier_hash) = verify_ownership(\n        spending_priv,\n        ephemeral_pub.x,\n        ephemeral_pub.y,\n        amount,\n        random,\n        leaf_index\n    );\n\n    // Commitments should match!\n    assert(commitment == sender_commitment);\n}\n","path":"/Users/chengchunyuan/project/hackathon/zVault/noir-circuits/utils/src/grumpkin.nr"}},"expression_width":{"Bounded":{"width":4}}}